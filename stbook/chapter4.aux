\relax 
\providecommand\hyper@newdestlabel[2]{}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Robust linear regression}{1}{chapter.1}}
\@writefile{lof}{\addvspace {2ex}}
\@writefile{lot}{\addvspace {2ex}}
\newlabel{chap:robreg}{{1}{1}{Robust linear regression}{chapter.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}The linear regression model}{1}{section.1.1}}
\newlabel{eq:linear_regr_model}{{1.1}{1}{The linear regression model}{equation.1.1.1}{}}
\newlabel{eq:linear_regr_model_sample}{{1.2}{1}{The linear regression model}{equation.1.1.2}{}}
\newlabel{eq:linear_regr_model_sample_bis}{{1.3}{1}{The linear regression model}{equation.1.1.3}{}}
\newlabel{eq:location_scale_regr_model}{{1.4}{2}{The linear regression model}{equation.1.1.4}{}}
\newlabel{eq:distr_function_yi}{{1.5}{2}{The linear regression model}{equation.1.1.5}{}}
\newlabel{eq:dens_function_yi}{{1.6}{2}{The linear regression model}{equation.1.1.6}{}}
\newlabel{eq:location_scale_model}{{1.7}{2}{The linear regression model}{equation.1.1.7}{}}
\citation{rousseeuw:leroy:1987}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Different types of outliers}{3}{section.1.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {\kern \digitwidth 1.1}{\ignorespaces Vertical outlier, good leverage point and bad leverage point}}{4}{section.1.2}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:outlier_types}{{1.1}{4}{Different types of outliers}{section.1.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}LS estimation}{4}{section.1.3}}
\citation{maronna:etal:2006}
\newlabel{eq:LS_min}{{1.8}{5}{LS estimation}{equation.1.3.8}{}}
\newlabel{eq:LS_equations}{{1.9}{5}{LS estimation}{equation.1.3.9}{}}
\newlabel{eq:LS_estimator}{{1.10}{5}{LS estimation}{equation.1.3.10}{}}
\newlabel{eq:regression_equivariance}{{1.11}{5}{LS estimation}{equation.1.3.11}{}}
\newlabel{eq:scale_equivariance}{{1.12}{5}{LS estimation}{equation.1.3.12}{}}
\newlabel{eq:affine_equivariance}{{1.13}{5}{LS estimation}{equation.1.3.13}{}}
\citation{edgeworth:1887}
\citation{huber:1981}
\citation{huber64}
\@writefile{toc}{\contentsline {section}{\numberline {1.4}M estimation}{6}{section.1.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.1}L\textsubscript  {1} or Least Absolute Deviation (LAD) estimation}{6}{subsection.1.4.1}}
\newlabel{eq:L1_min}{{1.14}{6}{L\textsubscript {1} or Least Absolute Deviation (LAD) estimation}{equation.1.4.14}{}}
\newlabel{eq:L1_equations}{{1.15}{6}{L\textsubscript {1} or Least Absolute Deviation (LAD) estimation}{equation.1.4.15}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.2}The principle of M estimation}{6}{subsection.1.4.2}}
\citation{huber64}
\newlabel{eq:M_min}{{1.16}{7}{The principle of M estimation}{equation.1.4.16}{}}
\newlabel{eq:Tukey_Biweight_function}{{1.17}{7}{The principle of M estimation}{equation.1.4.17}{}}
\citation{maronna:etal:2006}
\newlabel{eq:M_equations}{{1.18}{8}{The principle of M estimation}{equation.1.4.18}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {\kern \digitwidth 1.2}{\ignorespaces Huber loss function $\rho _{\kappa }^{\textsc  {\lowercase {H}}}$ and score function $\psi _{\kappa }^{\textsc  {\lowercase {H}}}$}}{9}{equation.1.4.18}}
\newlabel{fig:rho_psi_Huber}{{1.2}{9}{The principle of M estimation}{equation.1.4.18}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {\kern \digitwidth 1.3}{\ignorespaces Tukey-Biweight loss function $\rho _{\kappa }^{\textsc  {\lowercase {B}}}$ and score function $\psi _{\kappa }^{\textsc  {\lowercase {B}}}$}}{9}{equation.1.4.18}}
\newlabel{fig:rho_psi_Biweight}{{1.3}{9}{The principle of M estimation}{equation.1.4.18}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.3}M estimation as a generalization of maximum likelihood (ML) estimation}{9}{subsection.1.4.3}}
\newlabel{eq:ML_beta_sigma_min}{{1.19}{10}{M estimation as a generalization of maximum likelihood (ML) estimation}{equation.1.4.19}{}}
\newlabel{eq:ML_beta_min}{{1.20}{10}{M estimation as a generalization of maximum likelihood (ML) estimation}{equation.1.4.20}{}}
\newlabel{eq:ML_beta_sigma_equations}{{1.21}{10}{M estimation as a generalization of maximum likelihood (ML) estimation}{equation.1.4.21}{}}
\citation{maronna:etal:2006}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.4}Practical implementation of M estimates}{11}{subsection.1.4.4}}
\newlabel{subsec:practical_implementation_Mestimate}{{1.4.4}{11}{Practical implementation of M estimates}{subsection.1.4.4}{}}
\newlabel{eq:weighted_LS_equations}{{1.22}{11}{Practical implementation of M estimates}{equation.1.4.22}{}}
\@writefile{toc}{\contentsline {subsubsection}{Regression M estimate with preliminary scale estimation}{11}{section*.3}}
\citation{Koenker:1978}
\citation{Koenker:2005}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.5}Regression quantiles as regression M estimates}{12}{subsection.1.4.5}}
\newlabel{eq:quantile_regr_min}{{1.23}{12}{Regression quantiles as regression M estimates}{equation.1.4.23}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.6}Monotone vs. redescending M estimators}{12}{subsection.1.4.6}}
\citation{Mallows:1975}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4.7}GM estimation}{13}{subsection.1.4.7}}
\newlabel{eq:GM_equations_1}{{1.24}{13}{GM estimation}{equation.1.4.24}{}}
\newlabel{eq:GM_equations_2}{{1.25}{13}{GM estimation}{equation.1.4.25}{}}
\newlabel{eq:leverage}{{1.26}{13}{GM estimation}{equation.1.4.26}{}}
\citation{rousseeuw:leroy:1987}
\citation{Ronchetti:Rousseeuw:1985}
\citation{Maronna:1979}
\citation{maronna:etal:2006}
\citation{Theil:1950}
\citation{Brown:1951}
\citation{Sen:1968}
\citation{Jaeckel:1972}
\citation{Andrews:1974}
\citation{Siegel:1982}
\@writefile{toc}{\contentsline {section}{\numberline {1.5}Robust regression with a high breakdown point}{14}{section.1.5}}
\citation{Rousseeuw:1983}
\citation{rousseeuw&vdriessen99}
\citation{rousseeuw:1984}
\citation{rousseeuw:yohai:1984}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5.1}LTS and LMS estimation}{15}{subsection.1.5.1}}
\citation{rousseeuw:yohai:1984}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5.2}S estimation}{16}{subsection.1.5.2}}
\newlabel{eq:M_scale_equation}{{1.27}{16}{S estimation}{equation.1.5.27}{}}
\citation{rousseeuw:yohai:1984}
\citation{Hossjer:1992}
\newlabel{eq:M_scale_equation_res}{{1.28}{17}{S estimation}{equation.1.5.28}{}}
\newlabel{eq:S_Minequality_1}{{1.29}{17}{S estimation}{equation.1.5.29}{}}
\citation{yohai:1987}
\citation{Yohai:1988}
\citation{Mendes:1996}
\citation{Gervini:2002}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5.3}MM estimation}{18}{subsection.1.5.3}}
\newlabel{subsec:MM_estimation}{{1.5.3}{18}{MM estimation}{subsection.1.5.3}{}}
\newlabel{eq:MM_min}{{1.30}{18}{MM estimation}{equation.1.5.30}{}}
\citation{yohai:1987}
\citation{yohai:1987}
\citation{maronna:etal:2006}
\citation{maronna:etal:2006}
\citation{salibian:yohai:2006}
\newlabel{eq:MM_inequality}{{1.31}{19}{MM estimation}{equation.1.5.31}{}}
\newlabel{eq:MM_equations}{{1.32}{19}{MM estimation}{equation.1.5.32}{}}
\@writefile{toc}{\contentsline {subsubsection}{Numerical computation of the S and MM estimate}{19}{section*.4}}
\citation{rousseeuw:1984}
\citation{Salibian-Barrera:2004}
\newlabel{eq:S_min}{{1.33}{20}{Numerical computation of the S and MM estimate}{equation.1.5.33}{}}
\newlabel{eq:N}{{1.34}{20}{Numerical computation of the S and MM estimate}{equation.1.5.34}{}}
\citation{salibian:yohai:2006}
\citation{maronna:yohai:2000}
\newlabel{eq:S_algorithm}{{1.35}{21}{Numerical computation of the S and MM estimate}{equation.1.5.35}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5.4}MS estimation}{21}{subsection.1.5.4}}
\citation{bramati:croux:2007}
\citation{Yohai:1979}
\citation{yohai:1987}
\citation{Salibian-Barrera:2004}
\citation{maronna:etal:2006}
\citation{Croux:2003}
\newlabel{eq:linear_regr_model_MS}{{1.36}{22}{MS estimation}{equation.1.5.36}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.6}Robust inference for M, S and MM estimators}{22}{section.1.6}}
\newlabel{sec:inference}{{1.6}{22}{Robust inference for M, S and MM estimators}{section.1.6}{}}
\citation{Croux:2003}
\citation{Hansen:1982}
\citation{Croux:2003}
\citation{Croux:2003}
\citation{Croux:2003}
\citation{Croux:2003}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.6.1}Asymptotic distribution of M, S and MM estimators}{23}{subsection.1.6.1}}
\newlabel{subsec:asymptotic_distr_M_S_MM_estimators}{{1.6.1}{23}{Asymptotic distribution of M, S and MM estimators}{subsection.1.6.1}{}}
\citation{Croux:2003}
\newlabel{eq:V_MM}{{1.37}{24}{Asymptotic distribution of M, S and MM estimators}{equation.1.6.37}{}}
\citation{Croux:2003}
\newlabel{eq:G_MM}{{1.38}{25}{Asymptotic distribution of M, S and MM estimators}{equation.1.6.38}{}}
\newlabel{eq:Omega_MM}{{1.39}{25}{Asymptotic distribution of M, S and MM estimators}{equation.1.6.39}{}}
\newlabel{eq:Avar_betahat_MM}{{1.40}{25}{Asymptotic distribution of M, S and MM estimators}{equation.1.6.40}{}}
\newlabel{eq:Avar_betahat_S}{{1.41}{25}{Asymptotic distribution of M, S and MM estimators}{equation.1.6.41}{}}
\newlabel{eq:Acov_betahat_MM_S}{{1.42}{25}{Asymptotic distribution of M, S and MM estimators}{equation.1.6.42}{}}
\newlabel{eq:A}{{1.43}{25}{Asymptotic distribution of M, S and MM estimators}{equation.1.6.43}{}}
\newlabel{eq:a}{{1.44}{25}{Asymptotic distribution of M, S and MM estimators}{equation.1.6.44}{}}
\newlabel{eq:A_S}{{1.45}{25}{Asymptotic distribution of M, S and MM estimators}{equation.1.6.45}{}}
\newlabel{eq:a_S}{{1.46}{25}{Asymptotic distribution of M, S and MM estimators}{equation.1.6.46}{}}
\newlabel{eq:Avar_betahat_LS}{{1.47}{26}{Asymptotic distribution of M, S and MM estimators}{equation.1.6.47}{}}
\newlabel{eq:A_a_LS}{{1.48}{26}{Asymptotic distribution of M, S and MM estimators}{equation.1.6.48}{}}
\citation{Croux:2003}
\newlabel{eq:Acov_betahat_LS_S}{{1.49}{27}{Asymptotic distribution of M, S and MM estimators}{equation.1.6.49}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.6.2}Robust confidence intervals and tests with robust regression estimators}{27}{subsection.1.6.2}}
\@writefile{toc}{\contentsline {subsubsection}{Inference for a single linear combination of the regression parameters}{28}{section*.5}}
\citation{Greene:1997}
\@writefile{toc}{\contentsline {subsubsection}{Inference for several linear combinations of the regression parameters}{29}{section*.6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.6.3}Robust R-squared}{29}{subsection.1.6.3}}
\newlabel{eq:R2_classic_SS}{{1.50}{29}{Robust R-squared}{equation.1.6.50}{}}
\citation{Anderson:1984}
\citation{Renaud:2010}
\citation{maronna:etal:2006}
\newlabel{eq:R2_classic_corr}{{1.51}{30}{Robust R-squared}{equation.1.6.51}{}}
\newlabel{eq:phi2}{{1.52}{30}{Robust R-squared}{equation.1.6.52}{}}
\newlabel{eq:R2_adj}{{1.53}{30}{Robust R-squared}{equation.1.6.53}{}}
\newlabel{eq:R2_rho}{{1.54}{30}{Robust R-squared}{equation.1.6.54}{}}
\citation{croux:dehon:2003}
\newlabel{eq:R2_S}{{1.55}{31}{Robust R-squared}{equation.1.6.55}{}}
\citation{Renaud:2010}
\citation{Renaud:2010}
\newlabel{eq:R2_w}{{1.56}{32}{Robust R-squared}{equation.1.6.56}{}}
\newlabel{eq:Rtilde2_w}{{1.57}{32}{Robust R-squared}{equation.1.6.57}{}}
\newlabel{eq:Rtilde2_w_a}{{1.58}{32}{Robust R-squared}{equation.1.6.58}{}}
\newlabel{eq:Rtilde2_w_a_adj}{{1.59}{32}{Robust R-squared}{equation.1.6.59}{}}
\citation{Hausman:1978}
\citation{Dehon:2012}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.6.4}Extension of the Hausman test to check for the presence of outliers}{33}{subsection.1.6.4}}
\newlabel{subsec:Hausman}{{1.6.4}{33}{Extension of the Hausman test to check for the presence of outliers}{subsection.1.6.4}{}}
\@writefile{toc}{\contentsline {subsubsection}{Some preliminary results}{34}{section*.7}}
\newlabel{eq:Hausman_sigmahat_S-MM}{{1.60}{34}{Some preliminary results}{equation.1.6.60}{}}
\newlabel{eq:Hausman_normality_S-MM}{{1.61}{34}{Some preliminary results}{equation.1.6.61}{}}
\citation{Omelka:2010}
\newlabel{eq:Hausman_sigmahat_S-LS}{{1.62}{35}{Some preliminary results}{equation.1.6.62}{}}
\newlabel{eq:Hausman_normality_S-LS}{{1.63}{35}{Some preliminary results}{equation.1.6.63}{}}
\@writefile{toc}{\contentsline {subsubsection}{Comparison of LS and S}{35}{section*.8}}
\newlabel{Hausman_SvsLS}{{1.64}{35}{Comparison of LS and S}{equation.1.6.64}{}}
\citation{maronna:etal:2006}
\citation{Omelka:2010}
\@writefile{toc}{\contentsline {subsubsection}{Comparison of S and MM}{36}{section*.9}}
\newlabel{Hausman_MMvsS}{{1.65}{36}{Comparison of S and MM}{equation.1.6.65}{}}
\citation{rousseeuw:leroy:1987}
\@writefile{toc}{\contentsline {section}{\numberline {1.7}Examples}{37}{section.1.7}}
\@writefile{toc}{\contentsline {subsubsection}{Comparing estimators}{37}{section*.10}}
\@writefile{lof}{\contentsline {figure}{\numberline {\kern \digitwidth 1.4}{\ignorespaces \leavevmode {\color  {red}Caption needed}}}{37}{section*.10}}
\newlabel{fig:stars_scatterplot}{{1.4}{37}{Comparing estimators}{section*.10}{}}
\@writefile{toc}{\contentsline {paragraph}{LTS}{38}{section*.11}}
\@writefile{toc}{\contentsline {paragraph}{LMS}{39}{section*.12}}
\@writefile{toc}{\contentsline {paragraph}{M-estimator}{39}{section*.13}}
\@writefile{toc}{\contentsline {paragraph}{GM-estimator}{40}{section*.14}}
\@writefile{toc}{\contentsline {paragraph}{S-estimator}{40}{section*.15}}
\@writefile{toc}{\contentsline {paragraph}{\textsc  {\lowercase {MM}} estimator}{41}{section*.16}}
\@writefile{toc}{\contentsline {subsubsection}{Identifying outliers}{42}{section*.17}}
\@writefile{toc}{\contentsline {section}{\numberline {1.8}Appendix 1: M-estimators of location and scale}{46}{section.1.8}}
\newlabel{sec:robreg:appendix1}{{1.8}{46}{Appendix 1: M-estimators of location and scale}{section.1.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.8.1}M-estimator of location}{46}{subsection.1.8.1}}
\citation{Huber:2009}
\citation{maronna:etal:2006}
\newlabel{eq:M_location_equation}{{1.66}{47}{M-estimator of location}{equation.1.8.66}{}}
\citation{Huber:2009}
\citation{maronna:etal:2006}
\citation{Croux:2003}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.8.2}M-estimator of scale}{48}{subsection.1.8.2}}
\newlabel{eq:M_scale_loc_equation}{{1.67}{48}{M-estimator of scale}{equation.1.8.67}{}}
\citation{Hansen:1982}
\@writefile{toc}{\contentsline {section}{\numberline {1.9}Appendix 2: Generalized Method of Moments (GMM) and asymptotic distributions of regression M, S and MM estimators}{49}{section.1.9}}
\newlabel{sec:robreg:appendix2}{{1.9}{49}{Appendix 2: Generalized Method of Moments (GMM) and asymptotic distributions of regression M, S and MM estimators}{section.1.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.9.1}GMM-estimation principle}{49}{subsection.1.9.1}}
\newlabel{Eq:GMM_moments_conditions}{{1.68}{49}{GMM-estimation principle}{equation.1.9.68}{}}
\newlabel{Eq:GMM_equations}{{1.69}{49}{GMM-estimation principle}{equation.1.9.69}{}}
\newlabel{Eq:GMM_estimator_normality}{{1.70}{49}{GMM-estimation principle}{equation.1.9.70}{}}
\newlabel{Eq:GMM_estimator_V}{{1.71}{49}{GMM-estimation principle}{equation.1.9.71}{}}
\newlabel{Eq:GMM_estimator_G_Omega}{{1.72}{49}{GMM-estimation principle}{equation.1.9.72}{}}
\citation{rousseeuw:yohai:1984}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.9.2}M-, S- and \textsc  {\lowercase {MM}} estimators as G\textsc  {\lowercase {MM}} estimators}{50}{subsection.1.9.2}}
\newlabel{Eq:GMM_equations_M}{{1.73}{50}{M-, S- and \stsc {MM} estimators as G\stsc {MM} estimators}{equation.1.9.73}{}}
\newlabel{Eq:GMM_moment_function_M}{{1.74}{50}{M-, S- and \stsc {MM} estimators as G\stsc {MM} estimators}{equation.1.9.74}{}}
\newlabel{eq:S_min_rho0}{{1.75}{50}{M-, S- and \stsc {MM} estimators as G\stsc {MM} estimators}{equation.1.9.75}{}}
\newlabel{Eq:GMM_equations_S}{{1.76}{50}{M-, S- and \stsc {MM} estimators as G\stsc {MM} estimators}{equation.1.9.76}{}}
\newlabel{Eq:GMM_equations_MM}{{1.77}{51}{M-, S- and \stsc {MM} estimators as G\stsc {MM} estimators}{equation.1.9.77}{}}
\newlabel{Eq:GMM_moment_function_MM}{{1.78}{52}{M-, S- and \stsc {MM} estimators as G\stsc {MM} estimators}{equation.1.9.78}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.9.3}Asymptotic variance matrix of an \textsc  {\lowercase {MM}} estimator}{52}{subsection.1.9.3}}
\@writefile{toc}{\contentsline {subsubsection}{If the observations $\mathopen {}\mathclose \bgroup \originalleft ( \mathbf  x_{i},y_{i}\aftergroup \egroup \originalright ) $, $i = 1, \dots  , n$, are generated by a stationary and ergodic process, and are independent (Assumption A1)}{52}{section*.18}}
\citation{Croux:2003}
\citation{Croux:2003}
\@writefile{toc}{\contentsline {subsubsection}{In absence of heteroskedasticity (Assumption A2)}{54}{section*.19}}
\@writefile{toc}{\contentsline {subsubsection}{If the distribution of the error terms is symmetric around zero (Assumption A3)}{54}{section*.20}}
\citation{yohai:1987}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.9.4}Asymptotic variance matrix of an S-estimator}{55}{subsection.1.9.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.9.5}Asymptotic variance matrix of an M-estimator}{55}{subsection.1.9.5}}
\@setckpt{chapter4}{
\setcounter{page}{57}
\setcounter{equation}{78}
\setcounter{enumi}{2}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{24}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{1}
\setcounter{section}{9}
\setcounter{subsection}{5}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{4}
\setcounter{table}{0}
\setcounter{Item}{6}
\setcounter{Hfootnote}{24}
\setcounter{bookmark@seq@number}{48}
\setcounter{NAT@ctr}{0}
\setcounter{ContinuedFloat}{0}
\setcounter{parentequation}{0}
\setcounter{section@level}{2}
\setcounter{nprt@mantissa@digitsbefore}{0}
\setcounter{nprt@mantissa@digitsafter}{0}
\setcounter{nprt@exponent@digitsbefore}{0}
\setcounter{nprt@exponent@digitsafter}{0}
\setcounter{nprt@digitsfirstblock}{0}
\setcounter{nprt@blockcnt}{0}
\setcounter{nprt@cntprint}{0}
\setcounter{todo}{8}
}
