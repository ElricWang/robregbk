\relax 
\providecommand\hyper@newdestlabel[2]{}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Robust linear regression}{59}{chapter.4}}
\@writefile{lof}{\addvspace {2ex}}
\@writefile{lot}{\addvspace {2ex}}
\newlabel{chap:robreg}{{4}{59}{Robust linear regression}{chapter.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}The linear regression model}{59}{section.4.1}}
\newlabel{eq:linear_regr_model}{{4.1}{59}{The linear regression model}{equation.4.1.1}{}}
\newlabel{eq:linear_regr_model_sample}{{4.2}{59}{The linear regression model}{equation.4.1.2}{}}
\newlabel{eq:linear_regr_model_sample_bis}{{4.3}{59}{The linear regression model}{equation.4.1.3}{}}
\newlabel{eq:location_scale_regr_model}{{4.4}{60}{The linear regression model}{equation.4.1.4}{}}
\newlabel{eq:distr_function_yi}{{4.5}{60}{The linear regression model}{equation.4.1.5}{}}
\newlabel{eq:dens_function_yi}{{4.6}{60}{The linear regression model}{equation.4.1.6}{}}
\newlabel{eq:location_scale_model}{{4.7}{60}{The linear regression model}{equation.4.1.7}{}}
\citation{rousseeuw:leroy:1987}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Different types of outliers}{61}{section.4.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {\kern \digitwidth 4.1}{\ignorespaces Vertical outlier, good leverage point and bad leverage point}}{62}{section.4.2}}
\newlabel{fig:outlier_types}{{4.1}{62}{Different types of outliers}{section.4.2}{}}
\citation{maronna:etal:2006}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}LS estimation}{63}{section.4.3}}
\newlabel{eq:LS_min}{{4.8}{63}{LS estimation}{equation.4.3.8}{}}
\newlabel{eq:LS_equations}{{4.9}{63}{LS estimation}{equation.4.3.9}{}}
\newlabel{eq:LS_estimator}{{4.10}{63}{LS estimation}{equation.4.3.10}{}}
\citation{edgeworth:1887}
\newlabel{eq:regression_equivariance}{{4.11}{64}{LS estimation}{equation.4.3.11}{}}
\newlabel{eq:scale_equivariance}{{4.12}{64}{LS estimation}{equation.4.3.12}{}}
\newlabel{eq:affine_equivariance}{{4.13}{64}{LS estimation}{equation.4.3.13}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}M estimation}{64}{section.4.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.1}L\textsubscript  {1} or Least Absolute Deviation (LAD) estimation}{64}{subsection.4.4.1}}
\newlabel{eq:L1_min}{{4.14}{64}{L\textsubscript {1} or Least Absolute Deviation (LAD) estimation}{equation.4.4.14}{}}
\newlabel{eq:L1_equations}{{4.15}{64}{L\textsubscript {1} or Least Absolute Deviation (LAD) estimation}{equation.4.4.15}{}}
\citation{huber:1981}
\citation{huber64}
\citation{huber64}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.2}The principle of M estimation}{65}{subsection.4.4.2}}
\newlabel{eq:M_min}{{4.16}{65}{The principle of M estimation}{equation.4.4.16}{}}
\newlabel{eq:Tukey_Biweight_function}{{4.17}{66}{The principle of M estimation}{equation.4.4.17}{}}
\newlabel{eq:M_equations}{{4.18}{66}{The principle of M estimation}{equation.4.4.18}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {\kern \digitwidth 4.2}{\ignorespaces Huber loss function $\rho _{\kappa }^{\textsc  {\lowercase {H}}}$ and score function $\psi _{\kappa }^{\textsc  {\lowercase {H}}}$}}{67}{equation.4.4.18}}
\newlabel{fig:rho_psi_Huber}{{4.2}{67}{The principle of M estimation}{equation.4.4.18}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {\kern \digitwidth 4.3}{\ignorespaces Tukey-Biweight loss function $\rho _{\kappa }^{\textsc  {\lowercase {B}}}$ and score function $\psi _{\kappa }^{\textsc  {\lowercase {B}}}$}}{67}{equation.4.4.18}}
\newlabel{fig:rho_psi_Biweight}{{4.3}{67}{The principle of M estimation}{equation.4.4.18}{}}
\citation{maronna:etal:2006}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.3}M estimation as a generalization of maximum likelihood (ML) estimation}{68}{subsection.4.4.3}}
\newlabel{eq:ML_beta_sigma_min}{{4.19}{68}{M estimation as a generalization of maximum likelihood (ML) estimation}{equation.4.4.19}{}}
\newlabel{eq:ML_beta_min}{{4.20}{68}{M estimation as a generalization of maximum likelihood (ML) estimation}{equation.4.4.20}{}}
\citation{maronna:etal:2006}
\newlabel{eq:ML_beta_sigma_equations}{{4.21}{69}{M estimation as a generalization of maximum likelihood (ML) estimation}{equation.4.4.21}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.4}Practical implementation of M estimates}{69}{subsection.4.4.4}}
\newlabel{subsec:practical_implementation_Mestimate}{{4.4.4}{69}{Practical implementation of M estimates}{subsection.4.4.4}{}}
\newlabel{eq:weighted_LS_equations}{{4.22}{69}{Practical implementation of M estimates}{equation.4.4.22}{}}
\@writefile{toc}{\contentsline {subsubsection}{Regression M estimate with preliminary scale estimation}{69}{section*.20}}
\citation{Koenker:1978}
\citation{Koenker:2005}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.5}Regression quantiles as regression M estimates}{70}{subsection.4.4.5}}
\newlabel{eq:quantile_regr_min}{{4.23}{70}{Regression quantiles as regression M estimates}{equation.4.4.23}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.6}Monotone vs. redescending M estimators}{70}{subsection.4.4.6}}
\citation{Mallows:1975}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.7}GM estimation}{71}{subsection.4.4.7}}
\newlabel{eq:GM_equations_1}{{4.24}{71}{GM estimation}{equation.4.4.24}{}}
\newlabel{eq:GM_equations_2}{{4.25}{71}{GM estimation}{equation.4.4.25}{}}
\citation{rousseeuw:leroy:1987}
\citation{Ronchetti:Rousseeuw:1985}
\citation{Maronna:1979}
\citation{maronna:etal:2006}
\citation{Theil:1950}
\citation{Brown:1951}
\citation{Sen:1968}
\citation{Jaeckel:1972}
\citation{Andrews:1974}
\citation{Siegel:1982}
\newlabel{eq:leverage}{{4.26}{72}{GM estimation}{equation.4.4.26}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.5}Robust regression with a high breakdown point}{72}{section.4.5}}
\citation{Rousseeuw:1983}
\citation{rousseeuw&vdriessen99}
\citation{rousseeuw:1984}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.1}LTS and LMS estimation}{73}{subsection.4.5.1}}
\citation{rousseeuw:yohai:1984}
\citation{rousseeuw:yohai:1984}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.2}S estimation}{74}{subsection.4.5.2}}
\citation{rousseeuw:yohai:1984}
\newlabel{eq:M_scale_equation}{{4.27}{75}{S estimation}{equation.4.5.27}{}}
\newlabel{eq:M_scale_equation_res}{{4.28}{75}{S estimation}{equation.4.5.28}{}}
\newlabel{eq:S_Minequality_1}{{4.29}{75}{S estimation}{equation.4.5.29}{}}
\citation{Hossjer:1992}
\citation{yohai:1987}
\citation{Yohai:1988}
\citation{Mendes:1996}
\citation{Gervini:2002}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.3}MM estimation}{76}{subsection.4.5.3}}
\newlabel{subsec:MM_estimation}{{4.5.3}{76}{MM estimation}{subsection.4.5.3}{}}
\citation{yohai:1987}
\citation{yohai:1987}
\citation{maronna:etal:2006}
\citation{maronna:etal:2006}
\newlabel{eq:MM_min}{{4.30}{77}{MM estimation}{equation.4.5.30}{}}
\newlabel{eq:MM_inequality}{{4.31}{77}{MM estimation}{equation.4.5.31}{}}
\newlabel{eq:MM_equations}{{4.32}{77}{MM estimation}{equation.4.5.32}{}}
\@writefile{toc}{\contentsline {subsubsection}{Numerical computation of the S- and MM-estimate}{77}{section*.21}}
\citation{salibian:yohai:2006}
\citation{rousseeuw:1984}
\newlabel{eq:S_min}{{4.33}{78}{Numerical computation of the S- and MM-estimate}{equation.4.5.33}{}}
\citation{Salibian-Barrera:2004}
\newlabel{eq:N}{{4.34}{79}{Numerical computation of the S- and MM-estimate}{equation.4.5.34}{}}
\newlabel{eq:S_algorithm}{{4.35}{79}{Numerical computation of the S- and MM-estimate}{equation.4.5.35}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.4}MS-estimation}{79}{subsection.4.5.4}}
\citation{maronna:etal:2006}
\newlabel{eq:linear_regr_model_MS}{{4.36}{80}{MS-estimation}{equation.4.5.36}{}}
\citation{Croux:2003}
\citation{Croux:2003}
\citation{Hansen:1982}
\citation{Croux:2003}
\citation{Croux:2003}
\citation{Croux:2003}
\@writefile{toc}{\contentsline {section}{\numberline {4.6}Robust inference for M-, S- and MM-estimators}{81}{section.4.6}}
\newlabel{sec:inference}{{4.6}{81}{Robust inference for M-, S- and MM-estimators}{section.4.6}{}}
\citation{Croux:2003}
\citation{Croux:2003}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.1}Asymptotic distribution of M-, S- and MM-estimators}{82}{subsection.4.6.1}}
\newlabel{subsec:asymptotic_distr_M_S_MM_estimators}{{4.6.1}{82}{Asymptotic distribution of M-, S- and MM-estimators}{subsection.4.6.1}{}}
\newlabel{eq:V_MM}{{4.37}{83}{Asymptotic distribution of M-, S- and MM-estimators}{equation.4.6.37}{}}
\newlabel{eq:G_MM}{{4.38}{83}{Asymptotic distribution of M-, S- and MM-estimators}{equation.4.6.38}{}}
\newlabel{eq:Omega_MM}{{4.39}{83}{Asymptotic distribution of M-, S- and MM-estimators}{equation.4.6.39}{}}
\newlabel{eq:Avar_betahat_MM}{{4.40}{83}{Asymptotic distribution of M-, S- and MM-estimators}{equation.4.6.40}{}}
\newlabel{eq:Avar_betahat_S}{{4.41}{83}{Asymptotic distribution of M-, S- and MM-estimators}{equation.4.6.41}{}}
\newlabel{eq:Acov_betahat_MM_S}{{4.42}{83}{Asymptotic distribution of M-, S- and MM-estimators}{equation.4.6.42}{}}
\newlabel{eq:A}{{4.43}{83}{Asymptotic distribution of M-, S- and MM-estimators}{equation.4.6.43}{}}
\newlabel{eq:a}{{4.44}{83}{Asymptotic distribution of M-, S- and MM-estimators}{equation.4.6.44}{}}
\newlabel{eq:A_S}{{4.45}{83}{Asymptotic distribution of M-, S- and MM-estimators}{equation.4.6.45}{}}
\newlabel{eq:a_S}{{4.46}{83}{Asymptotic distribution of M-, S- and MM-estimators}{equation.4.6.46}{}}
\citation{Croux:2003}
\citation{Croux:2003}
\newlabel{eq:Avar_betahat_LS}{{4.47}{85}{Asymptotic distribution of M-, S- and MM-estimators}{equation.4.6.47}{}}
\newlabel{eq:A_a_LS}{{4.48}{85}{Asymptotic distribution of M-, S- and MM-estimators}{equation.4.6.48}{}}
\newlabel{eq:Acov_betahat_LS_S}{{4.49}{85}{Asymptotic distribution of M-, S- and MM-estimators}{equation.4.6.49}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.2}Robust confidence intervals and tests with robust regression estimators}{86}{subsection.4.6.2}}
\@writefile{toc}{\contentsline {subsubsection}{Inference for a single linear combination of the regression parameters}{86}{section*.22}}
\@writefile{toc}{\contentsline {subsubsection}{Inference for several linear combinations of the regression parameters}{87}{section*.23}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.3}Robust $R^{2}$}{87}{subsection.4.6.3}}
\citation{Greene:1997}
\citation{Anderson:1984}
\citation{Renaud:2010}
\newlabel{eq:R2_classic_SS}{{4.50}{88}{Robust $R^{2}$}{equation.4.6.50}{}}
\newlabel{eq:R2_classic_corr}{{4.51}{88}{Robust $R^{2}$}{equation.4.6.51}{}}
\newlabel{eq:phi2}{{4.52}{88}{Robust $R^{2}$}{equation.4.6.52}{}}
\newlabel{eq:R2_adj}{{4.53}{88}{Robust $R^{2}$}{equation.4.6.53}{}}
\citation{maronna:etal:2006}
\citation{croux:dehon:2003}
\newlabel{eq:R2_rho}{{4.54}{89}{Robust $R^{2}$}{equation.4.6.54}{}}
\newlabel{eq:R2_S}{{4.55}{89}{Robust $R^{2}$}{equation.4.6.55}{}}
\citation{Renaud:2010}
\citation{Renaud:2010}
\newlabel{eq:R2_w}{{4.56}{90}{Robust $R^{2}$}{equation.4.6.56}{}}
\newlabel{eq:Rtilde2_w}{{4.57}{90}{Robust $R^{2}$}{equation.4.6.57}{}}
\newlabel{eq:Rtilde2_w_a}{{4.58}{90}{Robust $R^{2}$}{equation.4.6.58}{}}
\citation{Hausman:1978}
\newlabel{eq:Rtilde2_w_a_adj}{{4.59}{91}{Robust $R^{2}$}{equation.4.6.59}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.4}Extension of the Hausman test to check for the presence of outliers}{91}{subsection.4.6.4}}
\newlabel{subsec:Hausman}{{4.6.4}{91}{Extension of the Hausman test to check for the presence of outliers}{subsection.4.6.4}{}}
\citation{Dehon:2012}
\@writefile{toc}{\contentsline {subsubsection}{Some preliminary results}{92}{section*.24}}
\citation{Omelka:2010}
\newlabel{eq:Hausman_sigmahat_S-MM}{{4.60}{93}{Some preliminary results}{equation.4.6.60}{}}
\newlabel{eq:Hausman_normality_S-MM}{{4.61}{93}{Some preliminary results}{equation.4.6.61}{}}
\newlabel{eq:Hausman_sigmahat_S-LS}{{4.62}{93}{Some preliminary results}{equation.4.6.62}{}}
\newlabel{eq:Hausman_normality_S-LS}{{4.63}{93}{Some preliminary results}{equation.4.6.63}{}}
\@writefile{toc}{\contentsline {subsubsection}{Comparison of LS and S}{93}{section*.25}}
\citation{maronna:etal:2006}
\citation{Omelka:2010}
\newlabel{Hausman_SvsLS}{{4.64}{94}{Comparison of LS and S}{equation.4.6.64}{}}
\@writefile{toc}{\contentsline {subsubsection}{Comparison of S and MM}{94}{section*.26}}
\newlabel{Hausman_MMvsS}{{4.65}{94}{Comparison of S and MM}{equation.4.6.65}{}}
\citation{rousseeuw:leroy:1987}
\@writefile{toc}{\contentsline {section}{\numberline {4.7}Examples}{95}{section.4.7}}
\@writefile{toc}{\contentsline {subsubsection}{Comparing estimators}{95}{section*.27}}
\@writefile{lof}{\contentsline {figure}{\numberline {\kern \digitwidth 4.4}{\ignorespaces \leavevmode {\color  {red}Caption needed}}}{96}{section*.27}}
\newlabel{fig:stars_scatterplot}{{4.4}{96}{Comparing estimators}{section*.27}{}}
\@writefile{toc}{\contentsline {paragraph}{LTS}{96}{section*.28}}
\@writefile{toc}{\contentsline {paragraph}{LMS}{97}{section*.29}}
\@writefile{toc}{\contentsline {paragraph}{M-estimator}{97}{section*.30}}
\@writefile{toc}{\contentsline {paragraph}{GM-estimator}{98}{section*.31}}
\@writefile{toc}{\contentsline {paragraph}{S-estimator}{98}{section*.32}}
\@writefile{toc}{\contentsline {paragraph}{MM-estimator}{99}{section*.33}}
\@writefile{toc}{\contentsline {subsubsection}{Identifying outliers}{100}{section*.34}}
\citation{Huber:2009}
\citation{maronna:etal:2006}
\@writefile{toc}{\contentsline {section}{\numberline {4.8}Appendix 1: M-estimators of location and scale}{105}{section.4.8}}
\newlabel{sec:robreg:appendix1}{{4.8}{105}{Appendix 1: M-estimators of location and scale}{section.4.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.8.1}M-estimator of location}{105}{subsection.4.8.1}}
\newlabel{eq:M_location_equation}{{4.66}{105}{M-estimator of location}{equation.4.8.66}{}}
\citation{Huber:2009}
\citation{maronna:etal:2006}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.8.2}M-estimator of scale}{106}{subsection.4.8.2}}
\newlabel{eq:M_scale_loc_equation}{{4.67}{106}{M-estimator of scale}{equation.4.8.67}{}}
\citation{Croux:2003}
\citation{Hansen:1982}
\@writefile{toc}{\contentsline {section}{\numberline {4.9}Appendix 2: Generalized Method of Moments (GMM) and asymptotic distributions of regression M-, S- and MM-estimators}{107}{section.4.9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.9.1}GMM-estimation principle}{107}{subsection.4.9.1}}
\newlabel{Eq:GMM_moments_conditions}{{4.68}{107}{GMM-estimation principle}{equation.4.9.68}{}}
\newlabel{Eq:GMM_equations}{{4.69}{107}{GMM-estimation principle}{equation.4.9.69}{}}
\newlabel{Eq:GMM_estimator_normality}{{4.70}{107}{GMM-estimation principle}{equation.4.9.70}{}}
\newlabel{Eq:GMM_estimator_V}{{4.71}{108}{GMM-estimation principle}{equation.4.9.71}{}}
\newlabel{Eq:GMM_estimator_G_Omega}{{4.72}{108}{GMM-estimation principle}{equation.4.9.72}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.9.2}M-, S- and MM-estimators as GMM-estimators}{108}{subsection.4.9.2}}
\newlabel{Eq:GMM_equations_M}{{4.73}{108}{M-, S- and MM-estimators as GMM-estimators}{equation.4.9.73}{}}
\newlabel{Eq:GMM_moment_function_M}{{4.74}{108}{M-, S- and MM-estimators as GMM-estimators}{equation.4.9.74}{}}
\newlabel{eq:S_min_rho0}{{4.75}{108}{M-, S- and MM-estimators as GMM-estimators}{equation.4.9.75}{}}
\citation{rousseeuw:yohai:1984}
\newlabel{Eq:GMM_equations_S}{{4.76}{109}{M-, S- and MM-estimators as GMM-estimators}{equation.4.9.76}{}}
\newlabel{Eq:GMM_equations_MM}{{4.77}{109}{M-, S- and MM-estimators as GMM-estimators}{equation.4.9.77}{}}
\newlabel{Eq:GMM_moment_function_MM}{{4.78}{110}{M-, S- and MM-estimators as GMM-estimators}{equation.4.9.78}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.9.3}Asymptotic variance matrix of an MM-estimator}{110}{subsection.4.9.3}}
\@writefile{toc}{\contentsline {subsubsection}{If the observations $\mathopen {}\mathclose \bgroup \originalleft ( \mathbf  x_{i},y_{i}\aftergroup \egroup \originalright ) $, $i = 1, \dots  , n$, are generated by a stationary and ergodic process, and are independent (Assumption A1)}{110}{section*.35}}
\@writefile{toc}{\contentsline {subsubsection}{In absence of heteroskedasticity (Assumption A2)}{112}{section*.36}}
\@writefile{toc}{\contentsline {subsubsection}{If the distribution of the error terms is symmetric around zero (Assumption A3)}{112}{section*.37}}
\citation{Croux:2003}
\citation{Croux:2003}
\citation{yohai:1987}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.9.4}Asymptotic variance matrix of an S-estimator}{113}{subsection.4.9.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.9.5}Asymptotic variance matrix of an M-estimator}{114}{subsection.4.9.5}}
\@setckpt{chapter4}{
\setcounter{page}{115}
\setcounter{equation}{78}
\setcounter{enumi}{2}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{25}
\setcounter{mpfootnote}{0}
\setcounter{part}{3}
\setcounter{chapter}{4}
\setcounter{section}{9}
\setcounter{subsection}{5}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{4}
\setcounter{table}{0}
\setcounter{Item}{16}
\setcounter{Hfootnote}{40}
\setcounter{bookmark@seq@number}{103}
\setcounter{NAT@ctr}{0}
\setcounter{ContinuedFloat}{0}
\setcounter{parentequation}{0}
\setcounter{section@level}{2}
\setcounter{nprt@mantissa@digitsbefore}{0}
\setcounter{nprt@mantissa@digitsafter}{0}
\setcounter{nprt@exponent@digitsbefore}{0}
\setcounter{nprt@exponent@digitsafter}{0}
\setcounter{nprt@digitsfirstblock}{1}
\setcounter{nprt@blockcnt}{1}
\setcounter{nprt@cntprint}{0}
\setcounter{todo}{33}
}
