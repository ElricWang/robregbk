\relax 
\providecommand\hyper@newdestlabel[2]{}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Robust linear regression}{57}{chapter.4}}
\@writefile{lof}{\addvspace {2ex}}
\@writefile{lot}{\addvspace {2ex}}
\newlabel{chap:robreg}{{4}{57}{Robust linear regression}{chapter.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}The linear regression model}{57}{section.4.1}}
\newlabel{eq:linear_regr_model}{{4.1}{57}{The linear regression model}{equation.4.1.1}{}}
\newlabel{eq:linear_regr_model_sample}{{4.2}{57}{The linear regression model}{equation.4.1.2}{}}
\newlabel{eq:linear_regr_model_sample_bis}{{4.3}{57}{The linear regression model}{equation.4.1.3}{}}
\newlabel{eq:location_scale_regr_model}{{4.4}{58}{The linear regression model}{equation.4.1.4}{}}
\newlabel{eq:distr_function_yi}{{4.5}{58}{The linear regression model}{equation.4.1.5}{}}
\newlabel{eq:dens_function_yi}{{4.6}{58}{The linear regression model}{equation.4.1.6}{}}
\newlabel{eq:location_scale_model}{{4.7}{58}{The linear regression model}{equation.4.1.7}{}}
\citation{rousseeuw:leroy:1987}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Different types of outliers}{59}{section.4.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {\kern \digitwidth 4.1}{\ignorespaces Vertical outlier, good leverage point and bad leverage point}}{60}{section.4.2}}
\newlabel{fig:outlier_types}{{4.1}{60}{Different types of outliers}{section.4.2}{}}
\citation{maronna:etal:2006}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}LS estimation}{61}{section.4.3}}
\newlabel{eq:LS_min}{{4.8}{61}{LS estimation}{equation.4.3.8}{}}
\newlabel{eq:LS_equations}{{4.9}{61}{LS estimation}{equation.4.3.9}{}}
\newlabel{eq:LS_estimator}{{4.10}{61}{LS estimation}{equation.4.3.10}{}}
\citation{edgeworth:1887}
\newlabel{eq:regression_equivariance}{{4.11}{62}{LS estimation}{equation.4.3.11}{}}
\newlabel{eq:scale_equivariance}{{4.12}{62}{LS estimation}{equation.4.3.12}{}}
\newlabel{eq:affine_equivariance}{{4.13}{62}{LS estimation}{equation.4.3.13}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}M estimation}{62}{section.4.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.1}L\textsubscript  {1} or Least Absolute Deviation (LAD) estimation}{62}{subsection.4.4.1}}
\newlabel{eq:L1_min}{{4.14}{62}{L\textsubscript {1} or Least Absolute Deviation (LAD) estimation}{equation.4.4.14}{}}
\newlabel{eq:L1_equations}{{4.15}{62}{L\textsubscript {1} or Least Absolute Deviation (LAD) estimation}{equation.4.4.15}{}}
\citation{huber:1981}
\citation{huber64}
\citation{huber64}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.2}The principle of M estimation}{63}{subsection.4.4.2}}
\newlabel{eq:M_min}{{4.16}{63}{The principle of M estimation}{equation.4.4.16}{}}
\newlabel{eq:Tukey_Biweight_function}{{4.17}{64}{The principle of M estimation}{equation.4.4.17}{}}
\newlabel{eq:M_equations}{{4.18}{64}{The principle of M estimation}{equation.4.4.18}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {\kern \digitwidth 4.2}{\ignorespaces Huber loss function $\rho _{\kappa }^{\textsc  {\lowercase {H}}}$ and score function $\psi _{\kappa }^{\textsc  {\lowercase {H}}}$}}{65}{equation.4.4.18}}
\newlabel{fig:rho_psi_Huber}{{4.2}{65}{The principle of M estimation}{equation.4.4.18}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {\kern \digitwidth 4.3}{\ignorespaces Tukey-Biweight loss function $\rho _{\kappa }^{\textsc  {\lowercase {B}}}$ and score function $\psi _{\kappa }^{\textsc  {\lowercase {B}}}$}}{65}{equation.4.4.18}}
\newlabel{fig:rho_psi_Biweight}{{4.3}{65}{The principle of M estimation}{equation.4.4.18}{}}
\citation{maronna:etal:2006}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.3}M estimation as a generalization of maximum likelihood (ML) estimation}{66}{subsection.4.4.3}}
\newlabel{eq:ML_beta_sigma_min}{{4.19}{66}{M estimation as a generalization of maximum likelihood (ML) estimation}{equation.4.4.19}{}}
\newlabel{eq:ML_beta_min}{{4.20}{66}{M estimation as a generalization of maximum likelihood (ML) estimation}{equation.4.4.20}{}}
\citation{maronna:etal:2006}
\newlabel{eq:ML_beta_sigma_equations}{{4.21}{67}{M estimation as a generalization of maximum likelihood (ML) estimation}{equation.4.4.21}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.4}Practical implementation of M estimates}{67}{subsection.4.4.4}}
\newlabel{subsec:practical_implementation_Mestimate}{{4.4.4}{67}{Practical implementation of M estimates}{subsection.4.4.4}{}}
\newlabel{eq:weighted_LS_equations}{{4.22}{67}{Practical implementation of M estimates}{equation.4.4.22}{}}
\@writefile{toc}{\contentsline {subsubsection}{Regression M estimate with preliminary scale estimation}{67}{section*.19}}
\citation{Koenker:1978}
\citation{Koenker:2005}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.5}Regression quantiles as regression M estimates}{68}{subsection.4.4.5}}
\newlabel{eq:quantile_regr_min}{{4.23}{68}{Regression quantiles as regression M estimates}{equation.4.4.23}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.6}Monotone vs. redescending M estimators}{68}{subsection.4.4.6}}
\citation{Mallows:1975}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.7}GM estimation}{69}{subsection.4.4.7}}
\newlabel{eq:GM_equations_1}{{4.24}{69}{GM estimation}{equation.4.4.24}{}}
\newlabel{eq:GM_equations_2}{{4.25}{69}{GM estimation}{equation.4.4.25}{}}
\citation{rousseeuw:leroy:1987}
\citation{Ronchetti:Rousseeuw:1985}
\citation{Maronna:1979}
\citation{maronna:etal:2006}
\citation{Theil:1950}
\citation{Brown:1951}
\citation{Sen:1968}
\citation{Jaeckel:1972}
\citation{Andrews:1974}
\citation{Siegel:1982}
\newlabel{eq:leverage}{{4.26}{70}{GM estimation}{equation.4.4.26}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.5}Robust regression with a high breakdown point}{70}{section.4.5}}
\citation{Rousseeuw:1983}
\citation{rousseeuw&vdriessen99}
\citation{rousseeuw:1984}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.1}LTS and LMS estimation}{71}{subsection.4.5.1}}
\citation{rousseeuw:yohai:1984}
\citation{rousseeuw:yohai:1984}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.2}S estimation}{72}{subsection.4.5.2}}
\citation{rousseeuw:yohai:1984}
\newlabel{eq:M_scale_equation}{{4.27}{73}{S estimation}{equation.4.5.27}{}}
\newlabel{eq:M_scale_equation_res}{{4.28}{73}{S estimation}{equation.4.5.28}{}}
\newlabel{eq:S_Minequality_1}{{4.29}{73}{S estimation}{equation.4.5.29}{}}
\citation{Hossjer:1992}
\citation{yohai:1987}
\citation{Yohai:1988}
\citation{Mendes:1996}
\citation{Gervini:2002}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.3}MM estimation}{74}{subsection.4.5.3}}
\newlabel{subsec:MM_estimation}{{4.5.3}{74}{MM estimation}{subsection.4.5.3}{}}
\citation{yohai:1987}
\citation{yohai:1987}
\citation{maronna:etal:2006}
\citation{maronna:etal:2006}
\newlabel{eq:MM_min}{{4.30}{75}{MM estimation}{equation.4.5.30}{}}
\newlabel{eq:MM_inequality}{{4.31}{75}{MM estimation}{equation.4.5.31}{}}
\newlabel{eq:MM_equations}{{4.32}{75}{MM estimation}{equation.4.5.32}{}}
\@writefile{toc}{\contentsline {subsubsection}{Numerical computation of the S- and MM-estimate}{75}{section*.20}}
\citation{salibian:yohai:2006}
\citation{rousseeuw:1984}
\newlabel{eq:S_min}{{4.33}{76}{Numerical computation of the S- and MM-estimate}{equation.4.5.33}{}}
\citation{Salibian-Barrera:2004}
\newlabel{eq:N}{{4.34}{77}{Numerical computation of the S- and MM-estimate}{equation.4.5.34}{}}
\newlabel{eq:S_algorithm}{{4.35}{77}{Numerical computation of the S- and MM-estimate}{equation.4.5.35}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.4}MS-estimation}{77}{subsection.4.5.4}}
\citation{maronna:etal:2006}
\newlabel{eq:linear_regr_model_MS}{{4.36}{78}{MS-estimation}{equation.4.5.36}{}}
\citation{Croux:2003}
\citation{Croux:2003}
\citation{Hansen:1982}
\citation{Croux:2003}
\citation{Croux:2003}
\citation{Croux:2003}
\@writefile{toc}{\contentsline {section}{\numberline {4.6}Robust inference for M-, S- and MM-estimators}{79}{section.4.6}}
\newlabel{sec:inference}{{4.6}{79}{Robust inference for M-, S- and MM-estimators}{section.4.6}{}}
\citation{Croux:2003}
\citation{Croux:2003}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.1}Asymptotic distribution of M-, S- and MM-estimators}{80}{subsection.4.6.1}}
\newlabel{subsec:asymptotic_distr_M_S_MM_estimators}{{4.6.1}{80}{Asymptotic distribution of M-, S- and MM-estimators}{subsection.4.6.1}{}}
\newlabel{eq:V_MM}{{4.37}{81}{Asymptotic distribution of M-, S- and MM-estimators}{equation.4.6.37}{}}
\newlabel{eq:G_MM}{{4.38}{81}{Asymptotic distribution of M-, S- and MM-estimators}{equation.4.6.38}{}}
\newlabel{eq:Omega_MM}{{4.39}{81}{Asymptotic distribution of M-, S- and MM-estimators}{equation.4.6.39}{}}
\newlabel{eq:Avar_betahat_MM}{{4.40}{81}{Asymptotic distribution of M-, S- and MM-estimators}{equation.4.6.40}{}}
\newlabel{eq:Avar_betahat_S}{{4.41}{81}{Asymptotic distribution of M-, S- and MM-estimators}{equation.4.6.41}{}}
\newlabel{eq:Acov_betahat_MM_S}{{4.42}{81}{Asymptotic distribution of M-, S- and MM-estimators}{equation.4.6.42}{}}
\newlabel{eq:A}{{4.43}{81}{Asymptotic distribution of M-, S- and MM-estimators}{equation.4.6.43}{}}
\newlabel{eq:a}{{4.44}{81}{Asymptotic distribution of M-, S- and MM-estimators}{equation.4.6.44}{}}
\newlabel{eq:A_S}{{4.45}{81}{Asymptotic distribution of M-, S- and MM-estimators}{equation.4.6.45}{}}
\newlabel{eq:a_S}{{4.46}{81}{Asymptotic distribution of M-, S- and MM-estimators}{equation.4.6.46}{}}
\citation{Croux:2003}
\citation{Croux:2003}
\newlabel{eq:Avar_betahat_LS}{{4.47}{83}{Asymptotic distribution of M-, S- and MM-estimators}{equation.4.6.47}{}}
\newlabel{eq:A_a_LS}{{4.48}{83}{Asymptotic distribution of M-, S- and MM-estimators}{equation.4.6.48}{}}
\newlabel{eq:Acov_betahat_LS_S}{{4.49}{83}{Asymptotic distribution of M-, S- and MM-estimators}{equation.4.6.49}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.2}Robust confidence intervals and tests with robust regression estimators}{84}{subsection.4.6.2}}
\@writefile{toc}{\contentsline {subsubsection}{Inference for a single linear combination of the regression parameters}{84}{section*.21}}
\@writefile{toc}{\contentsline {subsubsection}{Inference for several linear combinations of the regression parameters}{85}{section*.22}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.3}Robust $R^{2}$}{85}{subsection.4.6.3}}
\citation{Greene:1997}
\citation{Anderson:1984}
\citation{Renaud:2010}
\newlabel{eq:R2_classic_SS}{{4.50}{86}{Robust $R^{2}$}{equation.4.6.50}{}}
\newlabel{eq:R2_classic_corr}{{4.51}{86}{Robust $R^{2}$}{equation.4.6.51}{}}
\newlabel{eq:phi2}{{4.52}{86}{Robust $R^{2}$}{equation.4.6.52}{}}
\newlabel{eq:R2_adj}{{4.53}{86}{Robust $R^{2}$}{equation.4.6.53}{}}
\citation{maronna:etal:2006}
\citation{croux:dehon:2003}
\newlabel{eq:R2_rho}{{4.54}{87}{Robust $R^{2}$}{equation.4.6.54}{}}
\newlabel{eq:R2_S}{{4.55}{87}{Robust $R^{2}$}{equation.4.6.55}{}}
\citation{Renaud:2010}
\citation{Renaud:2010}
\newlabel{eq:R2_w}{{4.56}{88}{Robust $R^{2}$}{equation.4.6.56}{}}
\newlabel{eq:Rtilde2_w}{{4.57}{88}{Robust $R^{2}$}{equation.4.6.57}{}}
\newlabel{eq:Rtilde2_w_a}{{4.58}{88}{Robust $R^{2}$}{equation.4.6.58}{}}
\citation{Hausman:1978}
\newlabel{eq:Rtilde2_w_a_adj}{{4.59}{89}{Robust $R^{2}$}{equation.4.6.59}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.4}Extension of the Hausman test to check for the presence of outliers}{89}{subsection.4.6.4}}
\newlabel{subsec:Hausman}{{4.6.4}{89}{Extension of the Hausman test to check for the presence of outliers}{subsection.4.6.4}{}}
\citation{Dehon:2012}
\@writefile{toc}{\contentsline {subsubsection}{Some preliminary results}{90}{section*.23}}
\citation{Omelka:2010}
\newlabel{eq:Hausman_sigmahat_S-MM}{{4.60}{91}{Some preliminary results}{equation.4.6.60}{}}
\newlabel{eq:Hausman_normality_S-MM}{{4.61}{91}{Some preliminary results}{equation.4.6.61}{}}
\newlabel{eq:Hausman_sigmahat_S-LS}{{4.62}{91}{Some preliminary results}{equation.4.6.62}{}}
\newlabel{eq:Hausman_normality_S-LS}{{4.63}{91}{Some preliminary results}{equation.4.6.63}{}}
\@writefile{toc}{\contentsline {subsubsection}{Comparison of LS and S}{91}{section*.24}}
\citation{maronna:etal:2006}
\citation{Omelka:2010}
\newlabel{Hausman_SvsLS}{{4.64}{92}{Comparison of LS and S}{equation.4.6.64}{}}
\@writefile{toc}{\contentsline {subsubsection}{Comparison of S and MM}{92}{section*.25}}
\newlabel{Hausman_MMvsS}{{4.65}{92}{Comparison of S and MM}{equation.4.6.65}{}}
\citation{rousseeuw:leroy:1987}
\@writefile{toc}{\contentsline {section}{\numberline {4.7}Examples}{93}{section.4.7}}
\@writefile{toc}{\contentsline {subsubsection}{Comparing estimators}{93}{section*.26}}
\@writefile{lof}{\contentsline {figure}{\numberline {\kern \digitwidth 4.4}{\ignorespaces \leavevmode {\color  {red}Caption needed}}}{94}{section*.26}}
\newlabel{fig:stars_scatterplot}{{4.4}{94}{Comparing estimators}{section*.26}{}}
\@writefile{toc}{\contentsline {paragraph}{LTS}{94}{section*.27}}
\@writefile{toc}{\contentsline {paragraph}{LMS}{95}{section*.28}}
\@writefile{toc}{\contentsline {paragraph}{M-estimator}{95}{section*.29}}
\@writefile{toc}{\contentsline {paragraph}{GM-estimator}{96}{section*.30}}
\@writefile{toc}{\contentsline {paragraph}{S-estimator}{96}{section*.31}}
\@writefile{toc}{\contentsline {paragraph}{MM-estimator}{97}{section*.32}}
\@writefile{toc}{\contentsline {subsubsection}{Identifying outliers}{98}{section*.33}}
\citation{Huber:2009}
\citation{maronna:etal:2006}
\@writefile{toc}{\contentsline {section}{\numberline {4.8}Appendix 1: M-estimators of location and scale}{103}{section.4.8}}
\newlabel{sec:robreg:appendix1}{{4.8}{103}{Appendix 1: M-estimators of location and scale}{section.4.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.8.1}M-estimator of location}{103}{subsection.4.8.1}}
\newlabel{eq:M_location_equation}{{4.66}{103}{M-estimator of location}{equation.4.8.66}{}}
\citation{Huber:2009}
\citation{maronna:etal:2006}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.8.2}M-estimator of scale}{104}{subsection.4.8.2}}
\newlabel{eq:M_scale_loc_equation}{{4.67}{104}{M-estimator of scale}{equation.4.8.67}{}}
\citation{Croux:2003}
\citation{Hansen:1982}
\@writefile{toc}{\contentsline {section}{\numberline {4.9}Appendix 2: Generalized Method of Moments (GMM) and asymptotic distributions of regression M-, S- and MM-estimators}{105}{section.4.9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.9.1}GMM-estimation principle}{105}{subsection.4.9.1}}
\newlabel{Eq:GMM_moments_conditions}{{4.68}{105}{GMM-estimation principle}{equation.4.9.68}{}}
\newlabel{Eq:GMM_equations}{{4.69}{105}{GMM-estimation principle}{equation.4.9.69}{}}
\newlabel{Eq:GMM_estimator_normality}{{4.70}{105}{GMM-estimation principle}{equation.4.9.70}{}}
\newlabel{Eq:GMM_estimator_V}{{4.71}{106}{GMM-estimation principle}{equation.4.9.71}{}}
\newlabel{Eq:GMM_estimator_G_Omega}{{4.72}{106}{GMM-estimation principle}{equation.4.9.72}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.9.2}M-, S- and MM-estimators as GMM-estimators}{106}{subsection.4.9.2}}
\newlabel{Eq:GMM_equations_M}{{4.73}{106}{M-, S- and MM-estimators as GMM-estimators}{equation.4.9.73}{}}
\newlabel{Eq:GMM_moment_function_M}{{4.74}{106}{M-, S- and MM-estimators as GMM-estimators}{equation.4.9.74}{}}
\newlabel{eq:S_min_rho0}{{4.75}{106}{M-, S- and MM-estimators as GMM-estimators}{equation.4.9.75}{}}
\citation{rousseeuw:yohai:1984}
\newlabel{Eq:GMM_equations_S}{{4.76}{107}{M-, S- and MM-estimators as GMM-estimators}{equation.4.9.76}{}}
\newlabel{Eq:GMM_equations_MM}{{4.77}{107}{M-, S- and MM-estimators as GMM-estimators}{equation.4.9.77}{}}
\newlabel{Eq:GMM_moment_function_MM}{{4.78}{108}{M-, S- and MM-estimators as GMM-estimators}{equation.4.9.78}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.9.3}Asymptotic variance matrix of an MM-estimator}{108}{subsection.4.9.3}}
\@writefile{toc}{\contentsline {subsubsection}{If the observations $\mathopen {}\mathclose \bgroup \originalleft ( \mathbf  x_{i},y_{i}\aftergroup \egroup \originalright ) $, $i = 1, \dots  , n$, are generated by a stationary and ergodic process, and are independent (Assumption A1)}{108}{section*.34}}
\@writefile{toc}{\contentsline {subsubsection}{In absence of heteroskedasticity (Assumption A2)}{110}{section*.35}}
\@writefile{toc}{\contentsline {subsubsection}{If the distribution of the error terms is symmetric around zero (Assumption A3)}{110}{section*.36}}
\citation{Croux:2003}
\citation{Croux:2003}
\citation{yohai:1987}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.9.4}Asymptotic variance matrix of an S-estimator}{111}{subsection.4.9.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.9.5}Asymptotic variance matrix of an M-estimator}{112}{subsection.4.9.5}}
\@setckpt{chapter4}{
\setcounter{page}{113}
\setcounter{equation}{78}
\setcounter{enumi}{2}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{25}
\setcounter{mpfootnote}{0}
\setcounter{part}{3}
\setcounter{chapter}{4}
\setcounter{section}{9}
\setcounter{subsection}{5}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{4}
\setcounter{table}{0}
\setcounter{Item}{16}
\setcounter{Hfootnote}{38}
\setcounter{bookmark@seq@number}{104}
\setcounter{NAT@ctr}{0}
\setcounter{ContinuedFloat}{0}
\setcounter{parentequation}{0}
\setcounter{section@level}{2}
\setcounter{nprt@mantissa@digitsbefore}{0}
\setcounter{nprt@mantissa@digitsafter}{0}
\setcounter{nprt@exponent@digitsbefore}{0}
\setcounter{nprt@exponent@digitsafter}{0}
\setcounter{nprt@digitsfirstblock}{1}
\setcounter{nprt@blockcnt}{1}
\setcounter{nprt@cntprint}{0}
\setcounter{todo}{45}
}
