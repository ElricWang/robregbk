\relax 
\providecommand\hyper@newdestlabel[2]{}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Robust linear regression}{55}{chapter.4}}
\@writefile{lof}{\addvspace {2ex}}
\@writefile{lot}{\addvspace {2ex}}
\newlabel{chap:robreg}{{4}{55}{Robust linear regression}{chapter.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}The linear regression model}{55}{section.4.1}}
\newlabel{eq:linear_regr_model}{{4.1}{55}{The linear regression model}{equation.4.1.1}{}}
\newlabel{eq:linear_regr_model_sample}{{4.2}{55}{The linear regression model}{equation.4.1.2}{}}
\newlabel{eq:linear_regr_model_sample_bis}{{4.3}{55}{The linear regression model}{equation.4.1.3}{}}
\newlabel{eq:location_scale_regr_model}{{4.4}{56}{The linear regression model}{equation.4.1.4}{}}
\newlabel{eq:distr_function_yi}{{4.5}{56}{The linear regression model}{equation.4.1.5}{}}
\newlabel{eq:dens_function_yi}{{4.6}{56}{The linear regression model}{equation.4.1.6}{}}
\newlabel{eq:location_scale_model}{{4.7}{56}{The linear regression model}{equation.4.1.7}{}}
\citation{rousseeuw:leroy:1987}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Different types of outliers}{57}{section.4.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {\kern \digitwidth 4.1}{\ignorespaces Vertical outlier, good leverage point and bad leverage point}}{58}{section.4.2}}
\newlabel{fig:outlier_types}{{4.1}{58}{Different types of outliers}{section.4.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}LS estimation}{58}{section.4.3}}
\citation{maronna:etal:2006}
\newlabel{eq:LS_min}{{4.8}{59}{LS estimation}{equation.4.3.8}{}}
\newlabel{eq:LS_equations}{{4.9}{59}{LS estimation}{equation.4.3.9}{}}
\newlabel{eq:LS_estimator}{{4.10}{59}{LS estimation}{equation.4.3.10}{}}
\newlabel{eq:regression_equivariance}{{4.11}{59}{LS estimation}{equation.4.3.11}{}}
\newlabel{eq:scale_equivariance}{{4.12}{59}{LS estimation}{equation.4.3.12}{}}
\citation{edgeworth:1887}
\citation{huber:1981}
\newlabel{eq:affine_equivariance}{{4.13}{60}{LS estimation}{equation.4.3.13}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}M estimation}{60}{section.4.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.1}L\textsubscript  {1} or Least Absolute Deviation (LAD) estimation}{60}{subsection.4.4.1}}
\newlabel{eq:L1_min}{{4.14}{60}{L\textsubscript {1} or Least Absolute Deviation (LAD) estimation}{equation.4.4.14}{}}
\newlabel{eq:L1_equations}{{4.15}{60}{L\textsubscript {1} or Least Absolute Deviation (LAD) estimation}{equation.4.4.15}{}}
\citation{huber64}
\citation{huber64}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.2}The principle of M estimation}{61}{subsection.4.4.2}}
\newlabel{eq:M_min}{{4.16}{61}{The principle of M estimation}{equation.4.4.16}{}}
\newlabel{eq:Tukey_Biweight_function}{{4.17}{62}{The principle of M estimation}{equation.4.4.17}{}}
\newlabel{eq:M_equations}{{4.18}{62}{The principle of M estimation}{equation.4.4.18}{}}
\citation{maronna:etal:2006}
\@writefile{lof}{\contentsline {figure}{\numberline {\kern \digitwidth 4.2}{\ignorespaces Huber loss function $\rho _{\kappa }^{\textsc  {\lowercase {H}}}$ and score function $\psi _{\kappa }^{\textsc  {\lowercase {H}}}$}}{63}{equation.4.4.18}}
\newlabel{fig:rho_psi_Huber}{{4.2}{63}{The principle of M estimation}{equation.4.4.18}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {\kern \digitwidth 4.3}{\ignorespaces Tukey-Biweight loss function $\rho _{\kappa }^{\textsc  {\lowercase {B}}}$ and score function $\psi _{\kappa }^{\textsc  {\lowercase {B}}}$}}{63}{equation.4.4.18}}
\newlabel{fig:rho_psi_Biweight}{{4.3}{63}{The principle of M estimation}{equation.4.4.18}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.3}M estimation as a generalization of maximum likelihood (ML) estimation}{64}{subsection.4.4.3}}
\newlabel{eq:ML_beta_sigma_min}{{4.19}{64}{M estimation as a generalization of maximum likelihood (ML) estimation}{equation.4.4.19}{}}
\newlabel{eq:ML_beta_min}{{4.20}{64}{M estimation as a generalization of maximum likelihood (ML) estimation}{equation.4.4.20}{}}
\newlabel{eq:ML_beta_sigma_equations}{{4.21}{64}{M estimation as a generalization of maximum likelihood (ML) estimation}{equation.4.4.21}{}}
\citation{maronna:etal:2006}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.4}Practical implementation of M estimates}{65}{subsection.4.4.4}}
\newlabel{subsec:practical_implementation_Mestimate}{{4.4.4}{65}{Practical implementation of M estimates}{subsection.4.4.4}{}}
\newlabel{eq:weighted_LS_equations}{{4.22}{65}{Practical implementation of M estimates}{equation.4.4.22}{}}
\@writefile{toc}{\contentsline {subsubsection}{Regression M estimate with preliminary scale estimation}{65}{section*.19}}
\citation{Koenker:1978}
\citation{Koenker:2005}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.5}Regression quantiles as regression M estimates}{66}{subsection.4.4.5}}
\newlabel{eq:quantile_regr_min}{{4.23}{66}{Regression quantiles as regression M estimates}{equation.4.4.23}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.6}Monotone vs. redescending M estimators}{66}{subsection.4.4.6}}
\citation{Mallows:1975}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.7}GM estimation}{67}{subsection.4.4.7}}
\newlabel{eq:GM_equations_1}{{4.24}{67}{GM estimation}{equation.4.4.24}{}}
\newlabel{eq:GM_equations_2}{{4.25}{67}{GM estimation}{equation.4.4.25}{}}
\newlabel{eq:leverage}{{4.26}{67}{GM estimation}{equation.4.4.26}{}}
\citation{rousseeuw:leroy:1987}
\citation{Ronchetti:Rousseeuw:1985}
\citation{Maronna:1979}
\citation{maronna:etal:2006}
\citation{Theil:1950}
\citation{Brown:1951}
\citation{Sen:1968}
\citation{Jaeckel:1972}
\citation{Andrews:1974}
\citation{Siegel:1982}
\@writefile{toc}{\contentsline {section}{\numberline {4.5}Robust regression with a high breakdown point}{68}{section.4.5}}
\citation{Rousseeuw:1983}
\citation{rousseeuw&vdriessen99}
\citation{rousseeuw:1984}
\citation{rousseeuw:yohai:1984}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.1}LTS and LMS estimation}{69}{subsection.4.5.1}}
\citation{rousseeuw:yohai:1984}
\citation{rousseeuw:yohai:1984}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.2}S estimation}{70}{subsection.4.5.2}}
\newlabel{eq:M_scale_equation}{{4.27}{70}{S estimation}{equation.4.5.27}{}}
\newlabel{eq:M_scale_equation_res}{{4.28}{71}{S estimation}{equation.4.5.28}{}}
\newlabel{eq:S_Minequality_1}{{4.29}{71}{S estimation}{equation.4.5.29}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.3}MM-estimation}{72}{subsection.4.5.3}}
\newlabel{subsec:MM_estimation}{{4.5.3}{72}{MM-estimation}{subsection.4.5.3}{}}
\citation{yohai:1987}
\citation{maronna:etal:2006}
\citation{maronna:etal:2006}
\newlabel{eq:MM_min}{{4.30}{73}{MM-estimation}{equation.4.5.30}{}}
\newlabel{eq:MM_inequality}{{4.31}{73}{MM-estimation}{equation.4.5.31}{}}
\newlabel{eq:MM_equations}{{4.32}{73}{MM-estimation}{equation.4.5.32}{}}
\@writefile{toc}{\contentsline {subsubsection}{Numerical computation of the S- and MM-estimate}{73}{section*.20}}
\citation{rousseeuw:1984}
\newlabel{eq:S_min}{{4.33}{74}{Numerical computation of the S- and MM-estimate}{equation.4.5.33}{}}
\citation{Salibian-Barrera:2004}
\newlabel{eq:N}{{4.34}{75}{Numerical computation of the S- and MM-estimate}{equation.4.5.34}{}}
\newlabel{eq:S_algorithm}{{4.35}{75}{Numerical computation of the S- and MM-estimate}{equation.4.5.35}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.4}MS-estimation}{75}{subsection.4.5.4}}
\citation{maronna:etal:2006}
\newlabel{eq:linear_regr_model_MS}{{4.36}{76}{MS-estimation}{equation.4.5.36}{}}
\citation{Croux:2003}
\citation{Croux:2003}
\citation{Hansen:1982}
\citation{Croux:2003}
\citation{Croux:2003}
\citation{Croux:2003}
\@writefile{toc}{\contentsline {section}{\numberline {4.6}Robust inference for M-, S- and MM-estimators}{77}{section.4.6}}
\newlabel{sec:inference}{{4.6}{77}{Robust inference for M-, S- and MM-estimators}{section.4.6}{}}
\citation{Croux:2003}
\citation{Croux:2003}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.1}Asymptotic distribution of M-, S- and MM-estimators}{78}{subsection.4.6.1}}
\newlabel{subsec:asymptotic_distr_M_S_MM_estimators}{{4.6.1}{78}{Asymptotic distribution of M-, S- and MM-estimators}{subsection.4.6.1}{}}
\newlabel{eq:V_MM}{{4.37}{79}{Asymptotic distribution of M-, S- and MM-estimators}{equation.4.6.37}{}}
\newlabel{eq:G_MM}{{4.38}{79}{Asymptotic distribution of M-, S- and MM-estimators}{equation.4.6.38}{}}
\newlabel{eq:Omega_MM}{{4.39}{79}{Asymptotic distribution of M-, S- and MM-estimators}{equation.4.6.39}{}}
\newlabel{eq:Avar_betahat_MM}{{4.40}{79}{Asymptotic distribution of M-, S- and MM-estimators}{equation.4.6.40}{}}
\newlabel{eq:Avar_betahat_S}{{4.41}{79}{Asymptotic distribution of M-, S- and MM-estimators}{equation.4.6.41}{}}
\newlabel{eq:Acov_betahat_MM_S}{{4.42}{79}{Asymptotic distribution of M-, S- and MM-estimators}{equation.4.6.42}{}}
\newlabel{eq:A}{{4.43}{79}{Asymptotic distribution of M-, S- and MM-estimators}{equation.4.6.43}{}}
\newlabel{eq:a}{{4.44}{79}{Asymptotic distribution of M-, S- and MM-estimators}{equation.4.6.44}{}}
\newlabel{eq:A_S}{{4.45}{79}{Asymptotic distribution of M-, S- and MM-estimators}{equation.4.6.45}{}}
\newlabel{eq:a_S}{{4.46}{79}{Asymptotic distribution of M-, S- and MM-estimators}{equation.4.6.46}{}}
\citation{Croux:2003}
\citation{Croux:2003}
\newlabel{eq:Avar_betahat_LS}{{4.47}{81}{Asymptotic distribution of M-, S- and MM-estimators}{equation.4.6.47}{}}
\newlabel{eq:A_a_LS}{{4.48}{81}{Asymptotic distribution of M-, S- and MM-estimators}{equation.4.6.48}{}}
\newlabel{eq:Acov_betahat_LS_S}{{4.49}{81}{Asymptotic distribution of M-, S- and MM-estimators}{equation.4.6.49}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.2}Robust confidence intervals and tests with robust regression estimators}{82}{subsection.4.6.2}}
\@writefile{toc}{\contentsline {subsubsection}{Inference for a single linear combination of the regression parameters}{82}{section*.21}}
\@writefile{toc}{\contentsline {subsubsection}{Inference for several linear combinations of the regression parameters}{83}{section*.22}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.3}Robust $R^{2}$}{83}{subsection.4.6.3}}
\citation{Greene:1997}
\citation{Anderson:1984}
\citation{Renaud:2010}
\newlabel{eq:R2_classic_SS}{{4.50}{84}{Robust $R^{2}$}{equation.4.6.50}{}}
\newlabel{eq:R2_classic_corr}{{4.51}{84}{Robust $R^{2}$}{equation.4.6.51}{}}
\newlabel{eq:phi2}{{4.52}{84}{Robust $R^{2}$}{equation.4.6.52}{}}
\newlabel{eq:R2_adj}{{4.53}{84}{Robust $R^{2}$}{equation.4.6.53}{}}
\citation{maronna:etal:2006}
\citation{croux:dehon:2003}
\newlabel{eq:R2_rho}{{4.54}{85}{Robust $R^{2}$}{equation.4.6.54}{}}
\newlabel{eq:R2_S}{{4.55}{85}{Robust $R^{2}$}{equation.4.6.55}{}}
\citation{Renaud:2010}
\citation{Renaud:2010}
\newlabel{eq:R2_w}{{4.56}{86}{Robust $R^{2}$}{equation.4.6.56}{}}
\newlabel{eq:Rtilde2_w}{{4.57}{86}{Robust $R^{2}$}{equation.4.6.57}{}}
\newlabel{eq:Rtilde2_w_a}{{4.58}{86}{Robust $R^{2}$}{equation.4.6.58}{}}
\citation{Hausman:1978}
\newlabel{eq:Rtilde2_w_a_adj}{{4.59}{87}{Robust $R^{2}$}{equation.4.6.59}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.4}Extension of the Hausman test to check for the presence of outliers}{87}{subsection.4.6.4}}
\newlabel{subsec:Hausman}{{4.6.4}{87}{Extension of the Hausman test to check for the presence of outliers}{subsection.4.6.4}{}}
\citation{Dehon:2012}
\@writefile{toc}{\contentsline {subsubsection}{Some preliminary results}{88}{section*.23}}
\citation{Omelka:2010}
\newlabel{eq:Hausman_sigmahat_S-MM}{{4.60}{89}{Some preliminary results}{equation.4.6.60}{}}
\newlabel{eq:Hausman_normality_S-MM}{{4.61}{89}{Some preliminary results}{equation.4.6.61}{}}
\newlabel{eq:Hausman_sigmahat_S-LS}{{4.62}{89}{Some preliminary results}{equation.4.6.62}{}}
\newlabel{eq:Hausman_normality_S-LS}{{4.63}{89}{Some preliminary results}{equation.4.6.63}{}}
\@writefile{toc}{\contentsline {subsubsection}{Comparison of LS and S}{89}{section*.24}}
\citation{maronna:etal:2006}
\citation{Omelka:2010}
\newlabel{Hausman_SvsLS}{{4.64}{90}{Comparison of LS and S}{equation.4.6.64}{}}
\@writefile{toc}{\contentsline {subsubsection}{Comparison of S and MM}{90}{section*.25}}
\newlabel{Hausman_MMvsS}{{4.65}{90}{Comparison of S and MM}{equation.4.6.65}{}}
\citation{rousseeuw:leroy:1987}
\@writefile{toc}{\contentsline {section}{\numberline {4.7}Examples}{91}{section.4.7}}
\@writefile{toc}{\contentsline {subsubsection}{Comparing estimators}{91}{section*.26}}
\@writefile{lof}{\contentsline {figure}{\numberline {\kern \digitwidth 4.4}{\ignorespaces \leavevmode {\color  {red}Caption needed}}}{92}{section*.26}}
\newlabel{fig:stars_scatterplot}{{4.4}{92}{Comparing estimators}{section*.26}{}}
\@writefile{toc}{\contentsline {paragraph}{LTS}{92}{section*.27}}
\@writefile{toc}{\contentsline {paragraph}{LMS}{93}{section*.28}}
\@writefile{toc}{\contentsline {paragraph}{M-estimator}{93}{section*.29}}
\@writefile{toc}{\contentsline {paragraph}{GM-estimator}{94}{section*.30}}
\@writefile{toc}{\contentsline {paragraph}{S-estimator}{94}{section*.31}}
\@writefile{toc}{\contentsline {paragraph}{MM-estimator}{95}{section*.32}}
\@writefile{toc}{\contentsline {subsubsection}{Identifying outliers}{96}{section*.33}}
\@writefile{toc}{\contentsline {section}{\numberline {4.8}Appendix 1: M-estimators of location and scale}{100}{section.4.8}}
\newlabel{sec:robreg:appendix1}{{4.8}{100}{Appendix 1: M-estimators of location and scale}{section.4.8}{}}
\citation{Huber:2009}
\citation{maronna:etal:2006}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.8.1}M-estimator of location}{101}{subsection.4.8.1}}
\newlabel{eq:M_location_equation}{{4.66}{101}{M-estimator of location}{equation.4.8.66}{}}
\citation{Huber:2009}
\citation{maronna:etal:2006}
\citation{Croux:2003}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.8.2}M-estimator of scale}{102}{subsection.4.8.2}}
\newlabel{eq:M_scale_loc_equation}{{4.67}{102}{M-estimator of scale}{equation.4.8.67}{}}
\citation{Hansen:1982}
\@writefile{toc}{\contentsline {section}{\numberline {4.9}Appendix 2: Generalized Method of Moments (GMM) and asymptotic distributions of regression M-, S- and MM-estimators}{103}{section.4.9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.9.1}GMM-estimation principle}{103}{subsection.4.9.1}}
\newlabel{Eq:GMM_moments_conditions}{{4.68}{103}{GMM-estimation principle}{equation.4.9.68}{}}
\newlabel{Eq:GMM_equations}{{4.69}{103}{GMM-estimation principle}{equation.4.9.69}{}}
\newlabel{Eq:GMM_estimator_normality}{{4.70}{103}{GMM-estimation principle}{equation.4.9.70}{}}
\newlabel{Eq:GMM_estimator_V}{{4.71}{103}{GMM-estimation principle}{equation.4.9.71}{}}
\newlabel{Eq:GMM_estimator_G_Omega}{{4.72}{103}{GMM-estimation principle}{equation.4.9.72}{}}
\citation{rousseeuw:yohai:1984}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.9.2}M-, S- and MM-estimators as GMM-estimators}{104}{subsection.4.9.2}}
\newlabel{Eq:GMM_equations_M}{{4.73}{104}{M-, S- and MM-estimators as GMM-estimators}{equation.4.9.73}{}}
\newlabel{Eq:GMM_moment_function_M}{{4.74}{104}{M-, S- and MM-estimators as GMM-estimators}{equation.4.9.74}{}}
\newlabel{eq:S_min_rho0}{{4.75}{104}{M-, S- and MM-estimators as GMM-estimators}{equation.4.9.75}{}}
\newlabel{Eq:GMM_equations_S}{{4.76}{104}{M-, S- and MM-estimators as GMM-estimators}{equation.4.9.76}{}}
\newlabel{Eq:GMM_equations_MM}{{4.77}{105}{M-, S- and MM-estimators as GMM-estimators}{equation.4.9.77}{}}
\newlabel{Eq:GMM_moment_function_MM}{{4.78}{106}{M-, S- and MM-estimators as GMM-estimators}{equation.4.9.78}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.9.3}Asymptotic variance matrix of an MM-estimator}{106}{subsection.4.9.3}}
\@writefile{toc}{\contentsline {subsubsection}{If the observations $\mathopen {}\mathclose \bgroup \originalleft ( \mathbf  x_{i},y_{i}\aftergroup \egroup \originalright ) $, $i = 1, \dots  , n$, are generated by a stationary and ergodic process, and are independent (Assumption A1)}{106}{section*.34}}
\citation{Croux:2003}
\citation{Croux:2003}
\@writefile{toc}{\contentsline {subsubsection}{In absence of heteroskedasticity (Assumption A2)}{108}{section*.35}}
\@writefile{toc}{\contentsline {subsubsection}{If the distribution of the error terms is symmetric around zero (Assumption A3)}{108}{section*.36}}
\citation{yohai:1987}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.9.4}Asymptotic variance matrix of an S-estimator}{109}{subsection.4.9.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.9.5}Asymptotic variance matrix of an M-estimator}{109}{subsection.4.9.5}}
\@setckpt{chapter4}{
\setcounter{page}{111}
\setcounter{equation}{78}
\setcounter{enumi}{2}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{25}
\setcounter{mpfootnote}{0}
\setcounter{part}{3}
\setcounter{chapter}{4}
\setcounter{section}{9}
\setcounter{subsection}{5}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{4}
\setcounter{table}{0}
\setcounter{Item}{16}
\setcounter{Hfootnote}{38}
\setcounter{bookmark@seq@number}{102}
\setcounter{NAT@ctr}{0}
\setcounter{ContinuedFloat}{0}
\setcounter{parentequation}{0}
\setcounter{section@level}{2}
\setcounter{nprt@mantissa@digitsbefore}{0}
\setcounter{nprt@mantissa@digitsafter}{0}
\setcounter{nprt@exponent@digitsbefore}{0}
\setcounter{nprt@exponent@digitsafter}{0}
\setcounter{nprt@digitsfirstblock}{1}
\setcounter{nprt@blockcnt}{1}
\setcounter{nprt@cntprint}{0}
\setcounter{todo}{47}
}
