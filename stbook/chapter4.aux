\relax 
\providecommand\hyper@newdestlabel[2]{}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Robust linear regression}{59}{chapter.4}}
\@writefile{lof}{\addvspace {2ex}}
\@writefile{lot}{\addvspace {2ex}}
\newlabel{chap:robreg}{{4}{59}{Robust linear regression}{chapter.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}The linear regression model}{59}{section.4.1}}
\newlabel{eq:linear_regr_model}{{4.1}{59}{The linear regression model}{equation.4.1.1}{}}
\newlabel{eq:linear_regr_model_sample}{{4.2}{59}{The linear regression model}{equation.4.1.2}{}}
\newlabel{eq:linear_regr_model_sample_bis}{{4.3}{59}{The linear regression model}{equation.4.1.3}{}}
\newlabel{eq:location_scale_regr_model}{{4.4}{60}{The linear regression model}{equation.4.1.4}{}}
\newlabel{eq:distr_function_yi}{{4.5}{60}{The linear regression model}{equation.4.1.5}{}}
\newlabel{eq:dens_function_yi}{{4.6}{60}{The linear regression model}{equation.4.1.6}{}}
\newlabel{eq:location_scale_model}{{4.7}{60}{The linear regression model}{equation.4.1.7}{}}
\citation{rousseeuw:leroy:1987}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Different types of outliers}{61}{section.4.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {\kern \digitwidth 4.1}{\ignorespaces Vertical outlier, good leverage point and bad leverage point}}{62}{section.4.2}}
\newlabel{fig:outlier_types}{{4.1}{62}{Different types of outliers}{section.4.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}LS estimation}{62}{section.4.3}}
\citation{maronna:etal:2006}
\newlabel{eq:LS_min}{{4.8}{63}{LS estimation}{equation.4.3.8}{}}
\newlabel{eq:LS_equations}{{4.9}{63}{LS estimation}{equation.4.3.9}{}}
\newlabel{eq:LS_estimator}{{4.10}{63}{LS estimation}{equation.4.3.10}{}}
\newlabel{eq:regression_equivariance}{{4.11}{63}{LS estimation}{equation.4.3.11}{}}
\newlabel{eq:scale_equivariance}{{4.12}{63}{LS estimation}{equation.4.3.12}{}}
\newlabel{eq:affine_equivariance}{{4.13}{63}{LS estimation}{equation.4.3.13}{}}
\citation{edgeworth:1887}
\citation{huber:1981}
\citation{huber64}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}M estimation}{64}{section.4.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.1}Least Absolute Deviation (LAD) estimation}{64}{subsection.4.4.1}}
\newlabel{eq:L1_min}{{4.14}{64}{Least Absolute Deviation (LAD) estimation}{equation.4.4.14}{}}
\newlabel{eq:L1_equations}{{4.15}{64}{Least Absolute Deviation (LAD) estimation}{equation.4.4.15}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.2}The principle of M estimation}{64}{subsection.4.4.2}}
\citation{huber64}
\newlabel{eq:M_min}{{4.16}{65}{The principle of M estimation}{equation.4.4.16}{}}
\newlabel{eq:Tukey_Biweight_function}{{4.17}{65}{The principle of M estimation}{equation.4.4.17}{}}
\citation{maronna:etal:2006}
\newlabel{eq:M_equations}{{4.18}{66}{The principle of M estimation}{equation.4.4.18}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {\kern \digitwidth 4.2}{\ignorespaces Huber loss function $\rho _{\kappa }^{\textsc  {\lowercase {H}}}$ and score function $\psi _{\kappa }^{\textsc  {\lowercase {H}}}$}}{67}{equation.4.4.18}}
\newlabel{fig:rho_psi_Huber}{{4.2}{67}{The principle of M estimation}{equation.4.4.18}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {\kern \digitwidth 4.3}{\ignorespaces Tukey-Biweight loss function $\rho _{\kappa }^{\textsc  {\lowercase {B}}}$ and score function $\psi _{\kappa }^{\textsc  {\lowercase {B}}}$}}{67}{equation.4.4.18}}
\newlabel{fig:rho_psi_Biweight}{{4.3}{67}{The principle of M estimation}{equation.4.4.18}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.3}M estimation as a generalization of maximum likelihood (ML) estimation}{67}{subsection.4.4.3}}
\newlabel{eq:ML_beta_sigma_min}{{4.19}{68}{M estimation as a generalization of maximum likelihood (ML) estimation}{equation.4.4.19}{}}
\newlabel{eq:ML_beta_min}{{4.20}{68}{M estimation as a generalization of maximum likelihood (ML) estimation}{equation.4.4.20}{}}
\newlabel{eq:ML_beta_sigma_equations}{{4.21}{68}{M estimation as a generalization of maximum likelihood (ML) estimation}{equation.4.4.21}{}}
\citation{maronna:etal:2006}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.4}Practical implementation of M estimates}{69}{subsection.4.4.4}}
\newlabel{subsec:practical_implementation_Mestimate}{{4.4.4}{69}{Practical implementation of M estimates}{subsection.4.4.4}{}}
\newlabel{eq:weighted_LS_equations}{{4.22}{69}{Practical implementation of M estimates}{equation.4.4.22}{}}
\@writefile{toc}{\contentsline {subsubsection}{Regression M estimate with preliminary scale estimation}{69}{section*.20}}
\citation{Koenker:1978}
\citation{Koenker:2005}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.5}Regression quantiles as regression M estimates}{70}{subsection.4.4.5}}
\newlabel{eq:quantile_regr_min}{{4.23}{70}{Regression quantiles as regression M estimates}{equation.4.4.23}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.6}Monotone vs. redescending M estimators}{70}{subsection.4.4.6}}
\citation{Mallows:1975}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.7}GM estimation}{71}{subsection.4.4.7}}
\newlabel{eq:GM_equations_1}{{4.24}{71}{GM estimation}{equation.4.4.24}{}}
\newlabel{eq:GM_equations_2}{{4.25}{71}{GM estimation}{equation.4.4.25}{}}
\newlabel{eq:leverage}{{4.26}{71}{GM estimation}{equation.4.4.26}{}}
\citation{rousseeuw:leroy:1987}
\citation{Ronchetti:Rousseeuw:1985}
\citation{Maronna:1979}
\citation{maronna:etal:2006}
\citation{Theil:1950}
\citation{Brown:1951}
\citation{Sen:1968}
\citation{Jaeckel:1972}
\citation{Andrews:1974}
\citation{Siegel:1982}
\@writefile{toc}{\contentsline {section}{\numberline {4.5}Robust regression with a high breakdown point}{72}{section.4.5}}
\citation{Rousseeuw:1983}
\citation{rousseeuw&vdriessen99}
\citation{rousseeuw:1984}
\citation{rousseeuw:yohai:1984}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.1}LTS and LMS estimation}{73}{subsection.4.5.1}}
\citation{rousseeuw:yohai:1984}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.2}S estimation}{74}{subsection.4.5.2}}
\newlabel{eq:M_scale_equation}{{4.27}{74}{S estimation}{equation.4.5.27}{}}
\citation{rousseeuw:yohai:1984}
\citation{Hossjer:1992}
\newlabel{eq:M_scale_equation_res}{{4.28}{75}{S estimation}{equation.4.5.28}{}}
\newlabel{eq:S_Minequality_1}{{4.29}{75}{S estimation}{equation.4.5.29}{}}
\citation{yohai:1987}
\citation{Yohai:1988}
\citation{Mendes:1996}
\citation{Gervini:2002}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.3}MM estimation}{76}{subsection.4.5.3}}
\newlabel{subsec:MM_estimation}{{4.5.3}{76}{MM estimation}{subsection.4.5.3}{}}
\newlabel{eq:MM_min}{{4.30}{76}{MM estimation}{equation.4.5.30}{}}
\citation{yohai:1987}
\citation{yohai:1987}
\citation{maronna:etal:2006}
\citation{maronna:etal:2006}
\citation{salibian:yohai:2006}
\newlabel{eq:MM_inequality}{{4.31}{77}{MM estimation}{equation.4.5.31}{}}
\newlabel{eq:MM_equations}{{4.32}{77}{MM estimation}{equation.4.5.32}{}}
\@writefile{toc}{\contentsline {subsubsection}{Numerical computation of the S and MM estimate}{77}{section*.21}}
\citation{rousseeuw:1984}
\citation{Salibian-Barrera:2004}
\newlabel{eq:S_min}{{4.33}{78}{Numerical computation of the S and MM estimate}{equation.4.5.33}{}}
\newlabel{eq:N}{{4.34}{78}{Numerical computation of the S and MM estimate}{equation.4.5.34}{}}
\citation{salibian:yohai:2006}
\citation{maronna:yohai:2000}
\newlabel{eq:S_algorithm}{{4.35}{79}{Numerical computation of the S and MM estimate}{equation.4.5.35}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.4}MS estimation}{79}{subsection.4.5.4}}
\citation{bramati:croux:2007}
\citation{Yohai:1979}
\citation{yohai:1987}
\citation{Salibian-Barrera:2004}
\citation{maronna:etal:2006}
\citation{Croux:2003}
\citation{Croux:2003}
\citation{Hansen:1982}
\citation{Croux:2003}
\citation{Croux:2003}
\newlabel{eq:linear_regr_model_MS}{{4.36}{80}{MS estimation}{equation.4.5.36}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.6}Robust inference for M, S and MM estimators}{80}{section.4.6}}
\newlabel{sec:inference}{{4.6}{80}{Robust inference for M, S and MM estimators}{section.4.6}{}}
\citation{Croux:2003}
\citation{Croux:2003}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.1}Asymptotic distribution of M, S and MM estimators}{81}{subsection.4.6.1}}
\newlabel{subsec:asymptotic_distr_M_S_MM_estimators}{{4.6.1}{81}{Asymptotic distribution of M, S and MM estimators}{subsection.4.6.1}{}}
\citation{Croux:2003}
\newlabel{eq:V_MM}{{4.37}{82}{Asymptotic distribution of M, S and MM estimators}{equation.4.6.37}{}}
\citation{Croux:2003}
\newlabel{eq:G_MM}{{4.38}{83}{Asymptotic distribution of M, S and MM estimators}{equation.4.6.38}{}}
\newlabel{eq:Omega_MM}{{4.39}{83}{Asymptotic distribution of M, S and MM estimators}{equation.4.6.39}{}}
\newlabel{eq:Avar_betahat_MM}{{4.40}{83}{Asymptotic distribution of M, S and MM estimators}{equation.4.6.40}{}}
\newlabel{eq:Avar_betahat_S}{{4.41}{83}{Asymptotic distribution of M, S and MM estimators}{equation.4.6.41}{}}
\newlabel{eq:Acov_betahat_MM_S}{{4.42}{83}{Asymptotic distribution of M, S and MM estimators}{equation.4.6.42}{}}
\newlabel{eq:A}{{4.43}{83}{Asymptotic distribution of M, S and MM estimators}{equation.4.6.43}{}}
\newlabel{eq:a}{{4.44}{83}{Asymptotic distribution of M, S and MM estimators}{equation.4.6.44}{}}
\newlabel{eq:A_S}{{4.45}{83}{Asymptotic distribution of M, S and MM estimators}{equation.4.6.45}{}}
\newlabel{eq:a_S}{{4.46}{83}{Asymptotic distribution of M, S and MM estimators}{equation.4.6.46}{}}
\newlabel{eq:Avar_betahat_LS}{{4.47}{84}{Asymptotic distribution of M, S and MM estimators}{equation.4.6.47}{}}
\newlabel{eq:A_a_LS}{{4.48}{84}{Asymptotic distribution of M, S and MM estimators}{equation.4.6.48}{}}
\citation{Croux:2003}
\newlabel{eq:Acov_betahat_LS_S}{{4.49}{85}{Asymptotic distribution of M, S and MM estimators}{equation.4.6.49}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.2}Robust confidence intervals and tests with robust regression estimators}{85}{subsection.4.6.2}}
\@writefile{toc}{\contentsline {subsubsection}{Inference for a single linear combination of the regression parameters}{86}{section*.22}}
\citation{Greene:1997}
\@writefile{toc}{\contentsline {subsubsection}{Inference for several linear combinations of the regression parameters}{87}{section*.23}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.3}Robust R-squared}{87}{subsection.4.6.3}}
\newlabel{eq:R2_classic_SS}{{4.50}{87}{Robust R-squared}{equation.4.6.50}{}}
\citation{Anderson:1984}
\citation{Renaud:VictoriaFeser:2010}
\citation{maronna:etal:2006}
\citation{croux:dehon:2003}
\newlabel{eq:R2_classic_corr}{{4.51}{88}{Robust R-squared}{equation.4.6.51}{}}
\newlabel{eq:phi2}{{4.52}{88}{Robust R-squared}{equation.4.6.52}{}}
\newlabel{eq:R2_adj}{{4.53}{88}{Robust R-squared}{equation.4.6.53}{}}
\newlabel{eq:R2_rho}{{4.54}{88}{Robust R-squared}{equation.4.6.54}{}}
\citation{Renaud:VictoriaFeser:2010}
\citation{Renaud:VictoriaFeser:2010}
\newlabel{eq:R2_S}{{4.55}{89}{Robust R-squared}{equation.4.6.55}{}}
\newlabel{eq:R2_w}{{4.56}{89}{Robust R-squared}{equation.4.6.56}{}}
\newlabel{eq:Rtilde2_w}{{4.57}{89}{Robust R-squared}{equation.4.6.57}{}}
\citation{Renaud:VictoriaFeser:2010}
\citation{Renaud:VictoriaFeser:2010}
\newlabel{eq:Rtilde2_w_a}{{4.58}{90}{Robust R-squared}{equation.4.6.58}{}}
\newlabel{eq:Rtilde2_w_a_adj}{{4.59}{90}{Robust R-squared}{equation.4.6.59}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.4}Extension of the Hausman test to check for the presence of outliers}{90}{subsection.4.6.4}}
\newlabel{subsec:Hausman}{{4.6.4}{90}{Extension of the Hausman test to check for the presence of outliers}{subsection.4.6.4}{}}
\citation{Dehon:2009,Dehon:2012}
\citation{Hausman:1978}
\citation{Gervini:2002}
\citation{Dehon:2012}
\@writefile{toc}{\contentsline {subsubsection}{Some preliminary results}{91}{section*.24}}
\citation{Omelka:2010}
\newlabel{eq:Hausman_sigmahat_S-MM}{{4.60}{92}{Some preliminary results}{equation.4.6.60}{}}
\newlabel{eq:Hausman_normality_S-MM}{{4.61}{92}{Some preliminary results}{equation.4.6.61}{}}
\newlabel{eq:Hausman_sigmahat_S-LS}{{4.62}{92}{Some preliminary results}{equation.4.6.62}{}}
\newlabel{eq:Hausman_normality_S-LS}{{4.63}{92}{Some preliminary results}{equation.4.6.63}{}}
\citation{Dehon:2012}
\citation{maronna:etal:2006}
\citation{Omelka:2010}
\@writefile{toc}{\contentsline {subsubsection}{Comparison of LS and S}{93}{section*.25}}
\newlabel{Hausman_SvsLS}{{4.64}{93}{Comparison of LS and S}{equation.4.6.64}{}}
\@writefile{toc}{\contentsline {subsubsection}{Comparison of S and MM}{93}{section*.26}}
\citation{Dehon:2012}
\citation{rousseeuw:leroy:1987}
\newlabel{Hausman_MMvsS}{{4.65}{94}{Comparison of S and MM}{equation.4.6.65}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.7}Examples}{94}{section.4.7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.7.1}Comparing estimators}{94}{subsection.4.7.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {\kern \digitwidth 4.4}{\ignorespaces Effective temperatures and light intensities in star cluster CYG OB1}}{95}{subsection.4.7.1}}
\newlabel{fig:stars_scatterplot}{{4.4}{95}{Comparing estimators}{subsection.4.7.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{LTS}{96}{section*.27}}
\@writefile{toc}{\contentsline {subsubsection}{LMS}{96}{section*.28}}
\@writefile{toc}{\contentsline {subsubsection}{M estimator}{97}{section*.29}}
\@writefile{toc}{\contentsline {subsubsection}{GM estimator}{97}{section*.30}}
\@writefile{toc}{\contentsline {subsubsection}{S estimator}{98}{section*.31}}
\citation{sachs:warner:1997}
\@writefile{toc}{\contentsline {subsubsection}{MM estimator}{99}{section*.32}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.7.2}Identifying outliers}{100}{subsection.4.7.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {\kern \digitwidth 4.5}{\ignorespaces Outliers in the Sachs and Warner data}}{101}{subsection.4.7.2}}
\newlabel{fig:countries_S_standardized_res}{{4.5}{101}{Identifying outliers}{subsection.4.7.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.7.3}Testing for the presence of outliers and setting the efficiency for MM estimation}{102}{subsection.4.7.3}}
\@writefile{toc}{\contentsline {subsubsection}{MM estimation with 75\% efficiency}{103}{section*.33}}
\@writefile{toc}{\contentsline {subsubsection}{MM estimation with 85\% efficiency}{103}{section*.34}}
\@writefile{toc}{\contentsline {subsubsection}{MM estimation with 95\% efficiency}{104}{section*.35}}
\@writefile{toc}{\contentsline {subsubsection}{MM estimation with 99\% efficiency}{104}{section*.36}}
\citation{rousseeuw:zomeren:1990}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.7.4}Recognizing the type of outliers}{105}{subsection.4.7.4}}
\citation{Wooldridge:2001}
\citation{rousseeuw:zomeren:1990}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.7.5}Dealing with dummies}{107}{subsection.4.7.5}}
\@writefile{toc}{\contentsline {section}{\numberline {4.8}Appendix 1: M estimators of location and scale}{108}{section.4.8}}
\newlabel{sec:robreg:appendix1}{{4.8}{108}{Appendix 1: M estimators of location and scale}{section.4.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.8.1}M estimator of location}{108}{subsection.4.8.1}}
\citation{Huber:2009}
\citation{maronna:etal:2006}
\newlabel{eq:M_location_equation}{{4.66}{109}{M estimator of location}{equation.4.8.66}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.8.2}M estimator of scale}{109}{subsection.4.8.2}}
\newlabel{eq:M_scale_loc_equation}{{4.67}{109}{M estimator of scale}{equation.4.8.67}{}}
\citation{Huber:2009}
\citation{maronna:etal:2006}
\citation{Croux:2003}
\@writefile{toc}{\contentsline {section}{\numberline {4.9}Appendix 2: Generalized Method of Moments (GMM) and asymptotic distributions of regression M, S and MM estimators}{110}{section.4.9}}
\newlabel{sec:robreg:appendix2}{{4.9}{110}{Appendix 2: Generalized Method of Moments (GMM) and asymptotic distributions of regression M, S and MM estimators}{section.4.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.9.1}GMM estimation principle}{110}{subsection.4.9.1}}
\citation{Hansen:1982}
\newlabel{Eq:GMM_moments_conditions}{{4.68}{111}{GMM estimation principle}{equation.4.9.68}{}}
\newlabel{Eq:GMM_equations}{{4.69}{111}{GMM estimation principle}{equation.4.9.69}{}}
\newlabel{Eq:GMM_estimator_normality}{{4.70}{111}{GMM estimation principle}{equation.4.9.70}{}}
\newlabel{Eq:GMM_estimator_V}{{4.71}{111}{GMM estimation principle}{equation.4.9.71}{}}
\newlabel{Eq:GMM_estimator_G_Omega}{{4.72}{111}{GMM estimation principle}{equation.4.9.72}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.9.2}M, S and MM estimators as GMM estimators}{111}{subsection.4.9.2}}
\newlabel{Eq:GMM_equations_M}{{4.73}{111}{M, S and MM estimators as GMM estimators}{equation.4.9.73}{}}
\citation{rousseeuw:yohai:1984}
\newlabel{Eq:GMM_moment_function_M}{{4.74}{112}{M, S and MM estimators as GMM estimators}{equation.4.9.74}{}}
\newlabel{eq:S_min_rho0}{{4.75}{112}{M, S and MM estimators as GMM estimators}{equation.4.9.75}{}}
\newlabel{Eq:GMM_equations_S}{{4.76}{112}{M, S and MM estimators as GMM estimators}{equation.4.9.76}{}}
\newlabel{Eq:GMM_equations_MM}{{4.77}{113}{M, S and MM estimators as GMM estimators}{equation.4.9.77}{}}
\newlabel{Eq:GMM_moment_function_MM}{{4.78}{113}{M, S and MM estimators as GMM estimators}{equation.4.9.78}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.9.3}Asymptotic variance matrix of an MM estimator}{114}{subsection.4.9.3}}
\@writefile{toc}{\contentsline {subsubsection}{Assumption A1: The observations are generated by a stationary and ergodic process and are independent}{114}{section*.37}}
\citation{Croux:2003}
\@writefile{toc}{\contentsline {subsubsection}{Assumption A2: Absence of heteroskedasticity}{115}{section*.38}}
\citation{Croux:2003}
\citation{Croux:2003}
\citation{yohai:1987}
\@writefile{toc}{\contentsline {subsubsection}{Assumption A3: The distribution of the error terms is symmetric around zero}{116}{section*.39}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.9.4}Asymptotic variance matrix of an S estimator}{116}{subsection.4.9.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.9.5}Asymptotic variance matrix of an M estimator}{117}{subsection.4.9.5}}
\@setckpt{chapter4}{
\setcounter{page}{118}
\setcounter{equation}{78}
\setcounter{enumi}{2}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{22}
\setcounter{mpfootnote}{0}
\setcounter{part}{3}
\setcounter{chapter}{4}
\setcounter{section}{9}
\setcounter{subsection}{5}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{5}
\setcounter{table}{0}
\setcounter{Item}{16}
\setcounter{Hfootnote}{37}
\setcounter{bookmark@seq@number}{116}
\setcounter{NAT@ctr}{0}
\setcounter{ContinuedFloat}{0}
\setcounter{parentequation}{0}
\setcounter{section@level}{2}
\setcounter{nprt@mantissa@digitsbefore}{0}
\setcounter{nprt@mantissa@digitsafter}{0}
\setcounter{nprt@exponent@digitsbefore}{0}
\setcounter{nprt@exponent@digitsafter}{0}
\setcounter{nprt@digitsfirstblock}{1}
\setcounter{nprt@blockcnt}{1}
\setcounter{nprt@cntprint}{0}
\setcounter{todo}{41}
}
